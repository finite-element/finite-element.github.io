%% File generated by Sphinx clatex builder
\documentclass{book}


%% Added by Sphinx:
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[sc]{mathpazo}
\usepackage{sphinx}
\usepackage{amsthm}
\usepackage{amsmath,amssymb,amstext}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{hypcap}
\usepackage{longtable}
\usepackage{tabulary}
\usepackage{multirow}

\usepackage[margin=2.5cm]{geometry}

\renewcommand*{\familydefault}{\sfdefault}

\newtheorem{definition}{Definition}
\newtheorem{exercise}{Exercise}
\newtheorem{example}{Example}

\DeclareUnicodeCharacter{00A0}{~}

\setcounter{MaxMatrixCols}{20}

%% Sphinx: addition's end.



\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@fm\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vm\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@sa\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@dl\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ch\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@cpf\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\phantomsection\label{\detokenize{index::doc}}


\frontmatter


\chapter{M5MA47 Finite elements: analysis and implementation}
\label{\detokenize{index:finite-elements-analysis-and-implementation}}\label{\detokenize{index:m5ma47-finite-elements-analysis-and-implementation}}

\section{The implementation exercise}
\label{\detokenize{index:the-implementation-exercise}}
The object of the implementation exercise is to gain an understanding
of the finite element method by producing a working one and two
dimensional finite element solver library. Along the way you will have
the opportunity to pick up valuable scientific computing skills in
coding, software engineering and rigorous testing.

There will be no conventional lectures for this part of the
module. Instead, there will be twice weekly 1 hour computer lab sessions
during the term. Some of this time will involve explanations at the
board, but much of the time will be an opportunity to develop your
finite element implementation and receive help on how to do so.


\subsection{Formalities and marking scheme}
\label{\detokenize{index:formalities-and-marking-scheme}}
The implementation exercise is due at the end of term. That is, by
1600 on Friday 24 March. You must submit your work uploading the git
commit code on Blackboard. You can convenently find this code on the
commits page for your repository on github. For the avoidance of
doubt, the commit you submit must date from before the deadline!

The marking scheme will be as follows:
\begin{description}
\item[{High first/distinction (80-100)}] \leavevmode
As for bare first, but additionally the extension (mastery)
component of the implementaton exercise has been completed correctly
and clearly.

\item[{Bare first/distinction (70-80)}] \leavevmode
All parts of the implementation are correct and all tests pass. The
code style is always very clear and the implementation of every
exercise is transparent and elegant.

\item[{Upper second/merit (60-70)}] \leavevmode
The implementation is correct but let down somewhat by poor coding
style. Alternatively, submissions which are correct and well
written up to and including solving the Helmholtz problem but
which do not include a correct solution to boundary conditions will
earn an upper second.

\item[{Lower second/pass (50-60)}] \leavevmode
There are significant failings in the implementation resulting in
many test failures, and/or the coding style is
sufficiently poor that the code is hard to understand.

\item[{Fail (0-50)}] \leavevmode
The implementation is substantially incomplete. Correct
implementations may have been provided for some of the earlier exercises but
the more advanced parts of the implementation exercise have not been
attempted or do not work.

\end{description}


\subsection{Extension (mastery) exercise}
\label{\detokenize{index:extension-mastery-exercise}}
Completing the core implementation exercise will result in (at most) a
mark of 80\% for the implementation part of the module. The remaining
20\% will be allocated to an extension exercise which will be issued in
the middle of the term. This is intended to enable the students who
are doing best in the module to demonstrate their mastery of the
material by implementing work which goes beyond the main body of work.


\subsection{Obtaining the skeleton code}
\label{\detokenize{index:obtaining-the-skeleton-code}}
This section assumes you’ve already done the {\hyperref[\detokenize{tools:bitbucket-git}]{\sphinxcrossref{\DUrole{std,std-ref}{Git tutorial}}}}.


\subsubsection{Setting up your repository}
\label{\detokenize{index:setting-up-your-repository}}
We’re using a tool called \sphinxhref{https://classroom.github.com}{GitHub classroom} to automate the creation of your
copies of the repository. To obtain your copy click \sphinxhref{https://classroom.github.com/a/4GWLuxoA}{here}.


\subsubsection{Cloning a local copy}
\label{\detokenize{index:cloning-a-local-copy}}
At the command line on your working machine type:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{clone} \PYG{o}{\PYGZlt{}}\PYG{n}{url}\PYG{o}{\PYGZgt{}} \PYG{n}{finite}\PYG{o}{\PYGZhy{}}\PYG{n}{element}\PYG{o}{\PYGZhy{}}\PYG{n}{course}
\end{sphinxVerbatim}

Substituting your git repository url for \textless{}url\textgreater{}. Your git repository
url can be found by clicking on \sphinxtitleref{clone or download} at the top right of your repository page on GitHub. Next:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cd} \PYG{n}{finite}\PYG{o}{\PYGZhy{}}\PYG{n}{element}\PYG{o}{\PYGZhy{}}\PYG{n}{course}
\end{sphinxVerbatim}


\subsubsection{Setting up an implementation branch}
\label{\detokenize{index:setting-up-an-implementation-branch}}
We’ll keep the master branch of your repository in the original
condition so we can compare to it later, and collect any updates which
occur during the term. Instead, we’ll create an implementation branch
to actually work on:
\begin{quote}

git checkout -b implementation
\end{quote}

Your working directory is now a current checkout of your
implementation branch. You’ll also want to push this branch to GitHub:
\begin{quote}

git push \textendash{}set-upstream origin implementation
\end{quote}


\subsubsection{Setting up your venv}
\label{\detokenize{index:setting-up-your-venv}}
We’re going to use a Python venv. This is a private Python environment
in which we’ll install the packages we need, including our own
implementation exercise. This minimises interference between this
project and anything else which might be using Python on the
system. We don’t want to install the venv inside our git repository,
so type:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cd} \PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

Now we can run a script from the git repository to make the venv:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{.}\PYG{o}{/}\PYG{n}{finite}\PYG{o}{\PYGZhy{}}\PYG{n}{element}\PYG{o}{\PYGZhy{}}\PYG{n}{course}\PYG{o}{/}\PYG{n}{scripts}\PYG{o}{/}\PYG{n}{fe\PYGZus{}install\PYGZus{}venv} \PYG{n}{venv}
\end{sphinxVerbatim}


\subsubsection{Activating your venv}
\label{\detokenize{index:activating-your-venv}}
\sphinxstylestrong{Every time} you want to work on the implementation exercise, you need
to activate the venv. You do this with:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{source} \PYG{n}{venv}\PYG{o}{/}\PYG{n+nb}{bin}\PYG{o}{/}\PYG{n}{activate}
\end{sphinxVerbatim}

Obviously if you are typing this in a directory other than the one
containing the venv, you need to modify the path accordingly.


\subsubsection{Watching for updates and issues}
\label{\detokenize{index:watching-for-updates-and-issues}}
You should make sure you are notified of all updates on the main
repository and all issues anyone raises. For this, you should navigate
to \sphinxhref{https://github.com/finite-element/finite-element-course}{the main repository}. On the
top right there is an eye icon. Select the drop-down box and switch to
\sphinxcode{watching}.


\subsubsection{Updating your fork}
\label{\detokenize{index:updating-your-fork}}
When you see that the main repository has been updated, you’ll need to
update your repository to incorporate those changes. \sphinxstyleemphasis{Just this once},
you need to tell your local git repo about the main repository:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{remote} \PYG{n}{add} \PYG{n}{upstream} \PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{finite}\PYG{o}{\PYGZhy{}}\PYG{n}{element}\PYG{o}{/}\PYG{n}{finite}\PYG{o}{\PYGZhy{}}\PYG{n}{element}\PYG{o}{\PYGZhy{}}\PYG{n}{course}\PYG{o}{.}\PYG{n}{git}
\end{sphinxVerbatim}

Now, \sphinxstyleemphasis{every time} you want to update you do the following:
\begin{enumerate}
\item {} 
Make sure you have commited all your local changes \sphinxstylestrong{and} pushed
them to GitHub.

\item {} 
Execute the following commands:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{checkout} \PYG{n}{master}          \PYG{c+c1}{\PYGZsh{} Switch to the master branch.}
\PYG{n}{git} \PYG{n}{pull} \PYG{n}{upstream} \PYG{n}{master}     \PYG{c+c1}{\PYGZsh{} Update from the main repository.}
\PYG{n}{git} \PYG{n}{push}                     \PYG{c+c1}{\PYGZsh{} Push the updated master branch to GitHub.}
\PYG{n}{git} \PYG{n}{checkout} \PYG{n}{implementation}  \PYG{c+c1}{\PYGZsh{} Switch back to the implementation branch.}
\PYG{n}{git} \PYG{n}{merge} \PYG{n}{master}             \PYG{c+c1}{\PYGZsh{} Merge the new changes from master into implementation.}
\PYG{n}{git} \PYG{n}{push}                     \PYG{c+c1}{\PYGZsh{} Push the updated implementation branch to GitHub.}
\end{sphinxVerbatim}

\end{enumerate}


\subsubsection{Editing code}
\label{\detokenize{index:editing-code}}
In order to write the code required for the implementation exercise,
you’ll need to use a Python-aware text editor. There are many such
editors available and you can use any you like. The script which set
up the virtual environment installed \sphinxhref{https://pythonhosted.org/spyder/}{Spyder}, which is one good option. Other
editors are \sphinxhref{https://wiki.python.org/moin/PythonEditors}{listed here}. With your venv active,
you can launch spyder by typing:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{spyder3}
\end{sphinxVerbatim}

Don’t forget the 3. If you leave that off you’ll end up running an old
Python 2 version of Spyder which won’t know anything about your venv.


\subsection{Skeleton code documentation}
\label{\detokenize{index:skeleton-code-documentation}}
There is web documentation for the complete \DUrole{xref,std,std-doc}{fe\_utils}. There is
also an \DUrole{xref,std,std-ref}{alphabetical index} and a \DUrole{xref,std,std-ref}{search page}.


\subsection{How to do the implementation exercises}
\label{\detokenize{index:how-to-do-the-implementation-exercises}}
The implementation exercises build up a finite element library from
its component parts. Quite a lot of the coding infrastructure you will
need is provided already. Your task is to write the crucial
mathematical operations at key points. The mathematical operations
required are described on this website, interspersed with exercises
which require you to implement and test parts of the mathematics.

The code on which you will build is in the \sphinxcode{fe\_utils} directory of
your repository. The code has embedded documentation which is used to
build the \DUrole{xref,std,std-doc}{fe\_utils} web documentation.

As you do the exercises, \sphinxstylestrong{commit your code} to your repository. This
will build up your finite element library. You should commit code
early and often - small commits are easier to understand and debug
than large ones. \sphinxstylestrong{Never} commit back to the \sphinxcode{master} branch of your
fork, that should always remain a clean copy of the main repository.


\subsection{Pull requests for feedback}
\label{\detokenize{index:pull-requests-for-feedback}}
There will be a formal opportunity to recieve feedback on your code
progress twice during the term. To take part, you should set up a pull
request from your \sphinxcode{implementation} branch to the \sphinxcode{master} branch
of your repository. This will enable the lecturer to write line by
line comments on your code.


\subsubsection{Creating your pull request}
\label{\detokenize{index:creating-your-pull-request}}\begin{enumerate}
\item {} 
Click on the \sphinxcode{New pull request} button at the top of your
repository page on GitHub.

\item {} 
Make sure \sphinxstylestrong{left} dropdown box (“base”) is set to \sphinxcode{master}.

\item {} 
Make sure \sphinxstylestrong{right} dropdown box (“compare”) is set to \sphinxcode{implementation}.

\item {} 
Type a suitable title in the title box. For example
\sphinxcode{Request for feedback 30/1/15}.

\item {} 
If you have any comments you would like to pass on to the lecturer
(for example questions about how you should have done a particular
exercise) then type these in the \sphinxcode{Description} box.

\item {} 
Click \sphinxcode{Create pull request}.

\end{enumerate}


\subsection{Testing your work}
\label{\detokenize{index:testing-your-work}}
As you complete the exercises, there will often be test scripts which
exercise the code you have just written. These are located in the
\sphinxcode{test} directory and employ the \sphinxhref{http://pytest.org/}{pytest}
testing framework. You run the tests with:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{py}\PYG{o}{.}\PYG{n}{test} \PYG{n}{test\PYGZus{}script}\PYG{o}{.}\PYG{n}{py}
\end{sphinxVerbatim}

on the Bash command line or:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
!py.test test\PYGZus{}script.py
\end{sphinxVerbatim}

from within Python, replacing \sphinxcode{test\_script.py} with the appropriate
test file name. The \sphinxcode{-x} option to \sphinxcode{py.test} will cause the test
to stop at the first failure it finds, which is often the best place
to start fixing a problem. For those familiar with debuggers, the
\sphinxcode{-{-}pdb} option will drop you into the Python debugger at the first
error.

You can also run all the tests by running \sphinxcode{py.test} on the tests
directory. This works particularly well with the -x option, resulting
in the tests being run in course order and stopping at the first
failing test:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{py}\PYG{o}{.}\PYG{n}{test} \PYG{o}{\PYGZhy{}}\PYG{n}{x} \PYG{n}{tests}\PYG{o}{/}
\end{sphinxVerbatim}


\subsection{Coding style and commenting}
\label{\detokenize{index:coding-style-and-commenting}}
Computer code is not just functional, it also conveys information to
the reader. It is important to write clear, intelligible code. \sphinxstylestrong{The
readability and clarity of your code will count for marks}.

The Python community has agreed standards for coding, which are
documented in \sphinxhref{https://www.python.org/dev/peps/pep-0008/}{PEP8}. There are programs and
editor modes which can help you with this. The skeleton implementation
follows PEP8 quite closely. You are encouraged, especially if you are
a more experienced programmer, to follow PEP8 in your
implementation. However nobody is going to lose marks for PEP8
failures.


\subsection{Tips and tricks for the implementation exercise}
\label{\detokenize{index:tips-and-tricks-for-the-implementation-exercise}}\begin{description}
\item[{Work from the documentation.}] \leavevmode
The notes, and particularly the exercise specifications, contain
important information about how and what to implement. If you just
read the source code then you will miss out on important
information.

\item[{Read the hints}] \leavevmode
The pink sections in the notes starting with a lightbulb are
hints. Usually they contain suggestions about how to go about
writing your answer, or suggest Python functions which you might
find useful.

\item[{Don’t forget the 1D case}] \leavevmode
Your finite element library needs to work in one and two dimensions.

\item[{Return a \sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html\#numpy.array}{\sphinxcode{numpy.array()}}}] \leavevmode
Many of the functions you have to write return arrays. Make sure
you actually return an array and not a list (it’s usually fine to
build the answer as a list, but convert it to an array before you
return it).

\end{description}

\mainmatter


\chapter{Numerical quadrature}
\label{\detokenize{1_quadrature::doc}}\label{\detokenize{1_quadrature:numerical-quadrature}}
The core computational operation with which we are concerned in the
finite element method is the integration of a function over a known
reference element. It’s no big surprise, therefore, that this
operation will be at the heart of our finite element implementation.

The usual way to efficiently evaluate arbitrary integrals numerically
is numerical quadrature. This basic idea will already be familiar to
you from undergraduate maths (or maybe even high school calculus) as
it’s the generalisation of the trapezoidal rule and Simpson’s rule for
integration.

The core idea of quadrature is that the integral of a function
\(f(X)\) over an element \(e\) can be approximated as
a weighted sum of function values evaluated at particular points:

\phantomsection\label{\detokenize{1_quadrature:equation-quadrature}}\begin{equation}\label{equation:1_quadrature:quadrature}
\begin{split}\int_e f(X)  = \sum_{q} f(X_q) w_q + O(h^n)\end{split}
\end{equation}
we term the set \(\{X_q\}\) the set of \sphinxstyleemphasis{quadrature points} and the
corresponding set \(\{w_q\}\) the set of \sphinxstyleemphasis{quadrature weights}. A set of
quadrature points and their corresponding quadrature weights together
comprise a \sphinxstyleemphasis{quadrature rule} for \(e\). For an arbitrary function \(f\),
quadrature is only an approximation to the integral. The global
truncation error in this approximation is invariably of the form
\(O(h^n)\) where \(h\) is the diameter of the element.

If \(f\) is a polynomial in \(X\) with degree \(p\) such that
\(p\leq n-2\) then it is easy to show that integration using a
quadrature rule of degree \(n\) results in exactly zero error.

\phantomsection\label{\detokenize{1_quadrature:degree-of-precision}}
\begin{definition}
The \sphinxstyleemphasis{degree of precision} of a quadrature rule is the largest \(p\)
such that the quadrature rule integrates all polynomials of degree
\(p\) without error.
\end{definition}

\section{Exact and incomplete quadrature}
\label{\detokenize{1_quadrature:exact-and-incomplete-quadrature}}
In the finite element method, integrands are very frequently
polynomial. If the quadrature rule employed for a particular interval
has a sufficiently high degree of precision such that there is no
quadrature error in the integration, we refer to the quadrature as
\sphinxstyleemphasis{exact} or \sphinxstyleemphasis{complete}. In any other case we refer to the quadrature as
\sphinxstyleemphasis{incomplete}.

Typically, higher degree quadrature rules have more quadrature points
than lower degree rules. This results in a trade-off between the
accuracy of the quadrature rule and the number of function
evaluations, and hence the computational cost, of an integration using
that rule. Complete quadrature results in lower errors, but if the
error due to incomplete quadrature is small compared with other errors
in the simulation, particularly compared with the discretisation
error, then incomplete quadrature may be advantageous.


\section{Examples in one dimension}
\label{\detokenize{1_quadrature:examples-in-one-dimension}}
We noted above that a few one dimensional quadrature rules are commonly
taught in introductory integration courses. The first of these is the
midpoint rule:

\phantomsection\label{\detokenize{1_quadrature:equation-midpoint}}\begin{equation}\label{equation:1_quadrature:midpoint}
\begin{split}\int_0^h f(X) \mathrm{d} X = hf(0.5h) + O(h^3)\end{split}
\end{equation}
In other words, an approximation to the integral of
\(f\) over an interval can be calculated by multiplying the value
of \(f\) at the mid-point of the interval by the length of the
interval. This amounts to approximating the function over the integral
by a constant value.

If we improve our approximation of \(f\) to a straight line over
the interval, then we arrive at the trapezoidal (or trapezium) rule:

\phantomsection\label{\detokenize{1_quadrature:equation-trapezoidal}}\begin{equation}\label{equation:1_quadrature:trapezoidal}
\begin{split}\int_0^h f(X) \mathrm{d} X = \frac{h}{2}f(0) + \frac{h}{2}f(h) + O(h^4)\end{split}
\end{equation}
while if we employ a quadratic function then we arrive at Simpson’s rule:

\phantomsection\label{\detokenize{1_quadrature:equation-1_quadrature:0}}\begin{equation}\label{equation:1_quadrature:1_quadrature:0}
\begin{split}\int_0^h f(X) \mathrm{d} X = \frac{h}{6}f(0) + \frac{2h}{3}f\left(\frac{h}{2}\right) + \frac{h}{6}f(h) + O(h^5)\end{split}
\end{equation}

\section{Reference elements}
\label{\detokenize{1_quadrature:reference-elements}}
As a practical matter, we wish to write down quadrature rules as
arrays of numbers, independent of \(h\). In order to achieve this,
we will write the quadrature rules for a single, \sphinxstyleemphasis{reference
element}. When we wish to actually integrate a function over cell, we
will change coordinates to the reference cell. We will return to the
mechanics of this process later, but for now it means that we need
only consider quadrature rules on the reference cells we choose.

A commonly employed one dimensional reference cell is the unit
interval \([0,1]\), and that is the one we shall adopt here (the
other popular alternative is the interval \([-1, 1]\), which some
prefer due to its symmetry about the origin).

In two dimensions, the cells employed most commonly are triangles and
quadrilaterals. For simplicity, in this course we will only consider
implementing the finite element method on triangles. The choice of a
reference interval implies a natural choice of reference triangle. For
the unit interval the natural correspondence is with the triangle with
vertices \([(0,0), (1,0), (0,1)]\), though different choices of
vertex numbering are possible.


\section{Python implementations of reference elements}
\label{\detokenize{1_quadrature:python-implementations-of-reference-elements}}
The \sphinxcode{ReferenceCell} class provides
Python objects encoding the geometry and topology of the reference
cell. At this stage, the relevant information is the dimension of the
reference cell and the list of vertices. The topology will become
important when we consider {\hyperref[\detokenize{3_meshes::doc}]{\sphinxcrossref{\DUrole{doc}{meshes}}}}. The reference cells we will
require for this course are the
\sphinxcode{ReferenceInterval} and
\sphinxcode{ReferenceTriangle}.


\section{Quadrature rules on reference elements}
\label{\detokenize{1_quadrature:quadrature-rules-on-reference-elements}}
Having adopted a convention for the reference element, we can simply
express quadrature rules as lists of quadrature points with
corresponding quadrature weights. For example Simpson’s rule becomes:

\phantomsection\label{\detokenize{1_quadrature:equation-1_quadrature:1}}\begin{align}\label{equation:1_quadrature:1_quadrature:1}\!\begin{aligned}
w = \left[ \frac{1}{6}, \frac{2}{3}, \frac{1}{6} \right]\\
X = \left[ (0), (0.5), (1)\right].\\
\end{aligned}\end{align}
We choose to write the quadrature points as 1-tuples for consistency
with the \(n\)-dimensional case, in which the points will be
\(n\)-tuples.

The lowest order quadrature rule on the reference triangle is a single point
quadrature:

\phantomsection\label{\detokenize{1_quadrature:equation-1_quadrature:2}}\begin{align}\label{equation:1_quadrature:1_quadrature:2}\!\begin{aligned}
w = \left[ \frac{1}{2} \right]\\
X = \left[ \left(\frac{1}{3}, \frac{1}{3}  \right) \right]\\
\end{aligned}\end{align}
This rule has a degree of precision of 1.

\begin{sphinxadmonition}{hint}{Hint:}
The weights of a quadrature rule always sum to the volume of the
reference element. Why is this?
\end{sphinxadmonition}


\section{Legendre-Gauß quadrature in one dimension}
\label{\detokenize{1_quadrature:legendre-gausz-quadrature-in-one-dimension}}
The finite element method will result in integrands of different
polynomial degrees, so it is convenient if we have access to
quadrature rules of arbitrary degree on demand. In one dimension the
\sphinxhref{http://mathworld.wolfram.com/Legendre-GaussQuadrature.html}{Legendre-Gauß quadrature rules} are a
family of rules of arbitrary precision which we can employ for this
purpose. Helpfully, numpy provides \sphinxhref{http://docs.scipy.org/doc/numpy/reference/generated/numpy.polynomial.legendre.leggauss.html}{an implementation}
which we are able to adopt. The Legendre-Gauß quadrature rules are
usually defined for the interval \([-1, 1]\) so we need to change
coordinates in order to arrive at a quadrature rule for our reference
interval:

\phantomsection\label{\detokenize{1_quadrature:equation-1_quadrature:3}}\begin{align}\label{equation:1_quadrature:1_quadrature:3}\!\begin{aligned}
X_q = \frac{X'_q + 1}{2}\\
w_q = \frac{w'_q}{2}\\
\end{aligned}\end{align}
where \((\{X'_q\}, \{w'_q\})\) is the quadrature rule on the interval
\([-1, 1]\) and \((\{X_q\}, \{w_q\})\) is the rule on the unit interval.

Legendre-Gauß quadrature on the interval is optimal in the sense that it uses the
minimum possible number of points for each degree of precision.


\section{Extending Legendre-Gauß quadrature to two dimensions}
\label{\detokenize{1_quadrature:extending-legendre-gausz-quadrature-to-two-dimensions}}
We can form a unit square by taking the Cartesian product of two unit
intervals: \((0, 1)\otimes (0, 1)\). Similarly, we can form a quadrature
rule on a unit square by taking the product of two interval quadrature
rules:

\phantomsection\label{\detokenize{1_quadrature:equation-squarequad}}\begin{align}\label{equation:1_quadrature:squarequad}\!\begin{aligned}
X_\textrm{sq} = \left\{ (x_p, x_q)\ \middle|\ x_p, x_q \in X \right\}\\
w_\textrm{sq} = \left\{ w_p w_q\ \middle|\ w_p, w_q \in w \right\}\\
\end{aligned}\end{align}
where \((X, w)\) is an interval quadrature rule. Furthermore, the degree
of accuracy of \((X_\textrm{sq}, w_\textrm{sq})\) will be the same as
that of the one-dimensional rule.

However, we need a quadrature rule for the unit triangle. We can
achieve this by treating the triangle as a square with a zero length
edge. The Duffy transform maps the unit square to the unit triangle:

\phantomsection\label{\detokenize{1_quadrature:equation-1_quadrature:4}}\begin{equation}\label{equation:1_quadrature:1_quadrature:4}
\begin{split}(x_\textrm{tri},\ y_\textrm{tri}) =
  \left(x_\textrm{sq},\ y_\textrm{sq}(1 - x_\textrm{sq})\right)\end{split}
\end{equation}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.600\linewidth]{{duffy}.pdf}
\caption{The Duffy transform maps a square to a triangle by collapsing one side.}\label{\detokenize{1_quadrature:figduffy}}\label{\detokenize{1_quadrature:id1}}\end{figure}

By composing the Duffy transform with {\hyperref[\detokenize{1_quadrature:equation-squarequad}]{\sphinxcrossref{(8)}}} we can arrive
at a quadrature rule for the triangle:

\phantomsection\label{\detokenize{1_quadrature:equation-triquad}}\begin{align}\label{equation:1_quadrature:triquad}\!\begin{aligned}
X_\textrm{tri} =\left\{ \left(x_p, x_q(1 - x_p)\right)\ \middle|\ x_p \in X_h, x_q \in X_v \right\}\\
w_\textrm{tri} = \left\{ w_p w_q(1 - x_p)\ \middle|\ w_p \in w_h, w_q \in w_v \right\}\\
\end{aligned}\end{align}
where \((X_v, w_v)\) is a reference interval quadrature rule with degree
of precision \(n\) and \((X_h, w_h)\) is a reference interval quadrature
rule with degree of precision \(n+1\). The combined quadrature rule
\((X_\textrm{tri}, w_\textrm{tri})\) will then be \(n\). The additional
degree of precision required for \((X_h, w_h)\) is because the Duffy
transform effectively increases the polynomial degree of the integrand
by one.


\section{Implementing quadrature rules in Python}
\label{\detokenize{1_quadrature:implementing-quadrature-rules-in-python}}
The \sphinxcode{fe\_utils.quadrature} module provides the
\sphinxcode{QuadratureRule} class which records
quadrature points and weights for a given
\sphinxcode{ReferenceCell}. The
\sphinxcode{gauss\_quadrature()} function creates
quadrature rules for a prescribed degree of precision and reference
cell.

\phantomsection\label{\detokenize{1_quadrature:ex-integrate}}
\begin{exercise}
The \sphinxcode{integrate()} method is
left unimplemented. Using {\hyperref[\detokenize{1_quadrature:equation-quadrature}]{\sphinxcrossref{(1)}}}, implement this method.

A test script for your method is provided in the \sphinxcode{test} directory
as \sphinxcode{test\_integrate.py}. Run this script to test your code:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{py}\PYG{o}{.}\PYG{n}{test} \PYG{n}{test}\PYG{o}{/}\PYG{n}{test\PYGZus{}01\PYGZus{}integrate}\PYG{o}{.}\PYG{n}{py}
\end{sphinxVerbatim}

from the Bash command line or:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
!py.test test/test\PYGZus{}01\PYGZus{}integrate.py
\end{sphinxVerbatim}

from Python. Make sure you commit your modifications and push them
to your fork of the course repository.
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
You can implement
\sphinxcode{integrate()} in one line
using \sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.vectorize.html\#numpy.vectorize}{\sphinxcode{numpy.vectorize}} and \sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html\#numpy.dot}{\sphinxcode{numpy.dot()}}.
\end{sphinxadmonition}

\begin{sphinxadmonition}{hint}{Hint:}
Don’t forget to activate your Python venv!
\end{sphinxadmonition}


\chapter{Constructing finite elements}
\label{\detokenize{2_finite_elements::doc}}\label{\detokenize{2_finite_elements:secfinitelement}}\label{\detokenize{2_finite_elements:constructing-finite-elements}}
At the core of the finite element method is the representation of
finite-dimensional function spaces over elements. This concept was
formalised by \phantomsection\label{\detokenize{2_finite_elements:id1}}{\hyperref[\detokenize{zbibliography:ciarlet2002}]{\sphinxcrossref{{[}Cia02{]}}}}:

\phantomsection\label{\detokenize{2_finite_elements:def-ciarlet}}
\begin{definition}
A \sphinxstyleemphasis{finite element} is a triple \((K, P, N)\) in which \(K\) is a cell,
\(P\) is a space of functions \(K\rightarrow\mathbb{R}^n\) and \(N\), the
set of \sphinxstyleemphasis{nodes}, is a basis for \(P^*\), the \sphinxhref{http://mathworld.wolfram.com/DualVectorSpace.html}{dual space} to \(P\).
\end{definition}
Note that this definition includes a basis for \(P^*\), but not a
basis for \(P\). It turns out to be most convenient to specify the set
of nodes for an element, and then derive an appropriate basis for
\(P\) from that. In particular:

\begin{definition}
Let \(N = \{n_j\}\) be a basis for \(P^*\).  A \sphinxstyleemphasis{nodal
basis}, \(\{\phi_i\}\) for \(P\) is a basis for \(P\)
with the property that \(n_j(\phi_i) = \delta_{ij}\).
\end{definition}

\section{A worked example}
\label{\detokenize{2_finite_elements:a-worked-example}}
To illustrate the construction of a nodal basis, let’s consider the
linear polynomials on a triangle. We first need to define our
reference cell. The obvious choice is the triangle with vertices
\(\{(0,0), (1,0), (0,1)\}\)

Functions in this space have the form \(a + bx + cy\). So the
function space has three unknown parameters, and its basis (and dual
basis) will therefore have three members. In order to ensure the correct
continuity between elements, the dual basis we need to use is the
evaluation of the function at each of the cell vertices. That is:

\phantomsection\label{\detokenize{2_finite_elements:equation-2_finite_elements:0}}\begin{align}\label{equation:2_finite_elements:2_finite_elements:0}\!\begin{aligned}
n_0(f) = f\left((0,0)\right)\\
n_1(f) = f\left((1,0)\right)\\
n_2(f) = f\left((0,1)\right)\\
\end{aligned}\end{align}
We know that \(\phi_i\) has the form \(a + bx + cy\) so now we can
use the definition of the nodal basis to determine the unknown
coefficients:

\phantomsection\label{\detokenize{2_finite_elements:equation-2_finite_elements:1}}\begin{equation}\label{equation:2_finite_elements:2_finite_elements:1}
\begin{split}\begin{pmatrix}
n_0(\phi_i)\\
n_1(\phi_i)\\
n_2(\phi_i)
\end{pmatrix}
=
\begin{pmatrix}
\delta_{i,0}\\
\delta_{i,1}\\
\delta_{i,2}
\end{pmatrix}\end{split}
\end{equation}
So for \(\phi_0\) we have:

\phantomsection\label{\detokenize{2_finite_elements:equation-phimat}}\begin{equation}\label{equation:2_finite_elements:phimat}
\begin{split}\begin{bmatrix}
1 & 0 & 0\\
1 & 1 & 0\\
1 & 0 & 1\\
\end{bmatrix}
\begin{bmatrix}
a\\
b\\
c\\
\end{bmatrix}
=
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix}\end{split}
\end{equation}
Which has solution \(\phi_0 = 1 - x - y\). By a similar process,
we can establish that the full basis is given by:

\phantomsection\label{\detokenize{2_finite_elements:equation-2_finite_elements:2}}\begin{align}\label{equation:2_finite_elements:2_finite_elements:2}\!\begin{aligned}
\phi_0 = 1 - x - y\\
\phi_1 = x\\
\phi_2 = y\\
\end{aligned}\end{align}

\section{Types of node}
\label{\detokenize{2_finite_elements:types-of-node}}
We have just encountered nodes given by the evaluation of the function
at a given point. Other forms of functional are also suitable for use
as finite element nodes. Examples include the integral of the function
over the cell or some sub-entity and the evaluation of the gradient
of the function at some point. For some vector-valued function spaces,
the nodes may be given by the evaluation of the components of the
function normal or tangent to the boundary of the cell at some point.

In this course we will only consider point evaluation nodes. The implementation of several other forms of node are covered in \phantomsection\label{\detokenize{2_finite_elements:id2}}{\hyperref[\detokenize{zbibliography:kirby2004}]{\sphinxcrossref{{[}Kir04{]}}}}.


\section{The Lagrange element nodes}
\label{\detokenize{2_finite_elements:the-lagrange-element-nodes}}
The number of coefficients of a degree \(p\) polynomial in \(d\)
dimensions is given by \(\begin{pmatrix}p+d\\ d\end{pmatrix}\). The
simplest set of nodes which we can employ is simply to place these
nodes in a regular grid over the reference cell. Given the classical
relationship between binomial coefficients and \sphinxhref{http://mathworld.wolfram.com/PascalsTriangle.html}{Pascal’s triangle} (and between
trinomial coefficients and Pascal’s pyramid), it is unsurprising that
this produces the correct number of nodes.

The set of equally spaced points of degree \(p\) on the triangle is:

\phantomsection\label{\detokenize{2_finite_elements:equation-lattice}}\begin{equation}\label{equation:2_finite_elements:lattice}
\begin{split}\left\{\left(\frac{i}{p}, \frac{j}{p}\right)\middle| 0 \leq i+j \leq p\right\}\end{split}
\end{equation}
The finite elements with this set of nodes are called the \sphinxstyleemphasis{equispaced
Lagrange} elements and are the most commonly used elements for
relatively low order computations.

\begin{sphinxadmonition}{note}{Note:}
At higher order the equispaced Lagrange basis is poorly conditioned
and creates unwanted oscillations in the solutions. However for
this course Lagrange elements will be sufficient.
\end{sphinxadmonition}
\phantomsection\label{\detokenize{2_finite_elements:ex-lagrange-points}}
\begin{exercise}
Use {\hyperref[\detokenize{2_finite_elements:equation-lattice}]{\sphinxcrossref{(5)}}} to implement
\sphinxcode{lagrange\_points()}. Make sure your
algorithm also works for one-dimensional elements. Some basic tests
for your code are to be found in
\sphinxcode{test/test\_02\_lagrange\_points.py}. You can also test your lagrange
points on the triangle by running:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plot\PYGZus{}lagrange\PYGZus{}points} \PYG{n}{degree}
\end{sphinxVerbatim}

Where \sphinxcode{degree} is the degree of the points to plot.
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
The lagrange points can be generated very simply using \sphinxhref{https://docs.python.org/3/tutorial/datastructures.html\#list-comprehensions}{list
comprehensions}.
\end{sphinxadmonition}


\section{Solving for basis functions}
\label{\detokenize{2_finite_elements:sec-vandermonde}}\label{\detokenize{2_finite_elements:solving-for-basis-functions}}
The matrix in {\hyperref[\detokenize{2_finite_elements:equation-phimat}]{\sphinxcrossref{(3)}}} is a \sphinxstyleemphasis{generalised Vandermonde} %
\begin{footnote}[1]\sphinxAtStartFootnote
A \sphinxhref{http://mathworld.wolfram.com/VandermondeMatrix.html}{Vandermonde
matrix}
is the one-dimensional case of the generalised Vandermonde matrix.
%
\end{footnote}
matrix . Given a list of points \((x_i,y_i) \in \mathbb{R}^2, 0\leq i< m\)
the corresponding degree \(n\) generalised Vandermonde matrix is given by:

\phantomsection\label{\detokenize{2_finite_elements:equation-Vandermonde}}\begin{equation}\label{equation:2_finite_elements:Vandermonde}
\begin{split}\mathrm{V} =
\begin{bmatrix}
1 & x_0 & y_0 & x_0^2 & x_0y_0 & y_0^2 & \ldots & x_0^n & x_0^{n-1}y_0 & \ldots & x_0y_0^{n-1} & y_0^n \\
1 & x_1 & y_1 & x_1^2 & x_1y_1 & y_1^2 & \ldots & x_1^n & x_1^{n-1}y_1 & \ldots & x_1y_1^{n-1} & y_1^n \\
\vdots \\
1 & x_m & y_m & x_m^2 & x_my_m & y_m^2 & \ldots & x_m^n & x_m^{n-1}y_m & \ldots & x_my_m^{n-1} & y_m^n \\
\end{bmatrix}\end{split}
\end{equation}
If we construct the Vandermonde matrix for the nodes of a finite
element, then the equation for the complete set of basis function
polynomial coefficients is:

\phantomsection\label{\detokenize{2_finite_elements:equation-vdm-equation}}\begin{equation}\label{equation:2_finite_elements:vdm-equation}
\begin{split}\mathrm{V}\mathrm{C} = \mathrm{I}\end{split}
\end{equation}
where the \(j\)-th column of \(C\) contains the polynomial coefficients of
the basis function corresponding to the \(j\)-th node. For
{\hyperref[\detokenize{2_finite_elements:equation-vdm-equation}]{\sphinxcrossref{(7)}}} to be well-posed, there must be a number of nodes
equal to the number of coefficients of a degree \(n\) polynomial. If
this is the case, then it follows immediately that:

\phantomsection\label{\detokenize{2_finite_elements:equation-2_finite_elements:3}}\begin{equation}\label{equation:2_finite_elements:2_finite_elements:3}
\begin{split}\mathrm{C} = \mathrm{V}^{-1}\end{split}
\end{equation}
The same process applies to the construction of basis functions for
elements in one or three dimensions, except that the Vandermonde
matrix must be modified to exclude powers of \(y\) (in one dimension) or
to include powers of \(z\).

\begin{sphinxadmonition}{note}{Note:}
The power series basis for polynomial spaces employed here becomes
increasingly ill-conditioned at higher order, so it may be
advantageous to employ a different basis in the construction of the
Vandermonde matrix. See \phantomsection\label{\detokenize{2_finite_elements:id4}}{\hyperref[\detokenize{zbibliography:kirby2004}]{\sphinxcrossref{{[}Kir04{]}}}} for an example.
\end{sphinxadmonition}
\phantomsection\label{\detokenize{2_finite_elements:ex-vandermonde}}
\begin{exercise}
Use {\hyperref[\detokenize{2_finite_elements:equation-Vandermonde}]{\sphinxcrossref{(6)}}} to implement
\sphinxcode{vandermonde\_matrix()}. Think
carefully about how to loop over each row to construct the correct
powers of \(x\) and \(y\). For the purposes of this exercise you should
ignore the \sphinxcode{grad} argument.

Tests for this function are in \sphinxcode{test/test\_03\_vandermonde\_matrix.py}
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
You can use numpy array operations to construct whole columns of
the matrix at once.
\end{sphinxadmonition}


\section{Implementing finite elements in Python}
\label{\detokenize{2_finite_elements:implementing-finite-elements-in-python}}
The {\hyperref[\detokenize{2_finite_elements:def-ciarlet}]{\sphinxcrossref{\DUrole{std,std-ref}{Ciarlet triple}}}} \((K, P, N)\) also provides a
good abstraction for the implementation of software objects
corresponding to finite elements. In our case \(K\) will be a
\sphinxcode{ReferenceCell}. In this course we
will only implement finite element spaces consisting of complete
polynomial spaces so we will specify \(P\) by providing the maximum
degree of the polynomials in the space. Since we will only deal with
point evaluation nodes, we can represent \(N\) by a series of points at
which the evaluation should occur.

\phantomsection\label{\detokenize{2_finite_elements:ex-finite-element}}
\begin{exercise}
Implement the rest of the
\sphinxcode{FiniteElement} \sphinxcode{\_\_init\_\_()}
method. You should construct a Vandermonde matrix for the nodes and
invert it to create the basis function coefs. Store these as
\sphinxcode{self.basis\_coefs}.

Some basic tests of your implementation are in
\sphinxcode{test/test\_04\_init\_finite\_element.py}.
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
The \sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.inv.html\#numpy.linalg.inv}{\sphinxcode{numpy.linalg.inv()}} function may be
used to invert the matrix.
\end{sphinxadmonition}


\section{Implementing the Lagrange Elements}
\label{\detokenize{2_finite_elements:implementing-the-lagrange-elements}}
The \sphinxcode{FiniteElement} class implements
a general finite element object assuming we have provided the cell,
polynomial, degree and nodes. The
\sphinxcode{LagrangeElement} class is a
\sphinxhref{https://docs.python.org/3/tutorial/classes.html\#inheritance}{subclass} of
\sphinxcode{FiniteElement} which will implement
the particular case of the equispaced Lagrange elements.

\phantomsection\label{\detokenize{2_finite_elements:ex-lagrange-element}}
\begin{exercise}
Implement the \sphinxcode{\_\_init\_\_()} method of
\sphinxcode{LagrangeElement}. Use
\sphinxcode{lagrange\_points()} to obtain the
nodes. For the purpose of this exercise, you may ignore the
\sphinxcode{entity\_nodes} argument.

\sphinxstylestrong{After} you have implemented
\sphinxcode{tabulate()} in the
next exercise, you can use
\sphinxcode{plot\_lagrange\_basis\_functions} to visualise your
Lagrange basis functions.
\end{exercise}

\section{Tabulating basis functions}
\label{\detokenize{2_finite_elements:tabulating-basis-functions}}
A core operation in the finite element method is integrating
expressions involving functions in finite element spaces. This is
usually accomplished using {\hyperref[\detokenize{1_quadrature::doc}]{\sphinxcrossref{\DUrole{doc}{numerical quadrature}}}}. This means that we need to be able to evaluate the
basis functions at a set of quadrature points. The operation of
evaluating a set of basis functions at a set of points is called
\sphinxstyleemphasis{tabulation}.

\phantomsection\label{\detokenize{2_finite_elements:ex-tabulate}}
\begin{exercise}
Implement \sphinxcode{tabulate()}.
You can use a Vandermonde matrix to evaluate the polynomial terms
and take the matrix product of this with the basis function
coefficients. The method should have at most two executable
lines. For the purposes of this exercise, ignore the \sphinxcode{grad}
argument.

The test file \sphinxcode{test/test\_05\_tabulate.py} checks that tabulating the
nodes of a finite element produces the identity matrix.
\end{exercise}

\section{Gradients of basis functions}
\label{\detokenize{2_finite_elements:gradients-of-basis-functions}}
A function \(f\) defined over a single finite element with basis
\(\{\phi_i\}\) is represented by a weighted sum of that basis:
\begin{equation*}
\begin{split}f = \sum_i f_i\phi_i\end{split}
\end{equation*}
In order to be able to represent and solve PDEs, we will naturally
also have terms incorporating derivatives. Since the coefficients
\(f_i\) are spatially constant, derivative operators pass through to
apply to the basis functions:
\begin{equation*}
\begin{split}\nabla f  = \sum_i f_i\nabla\phi_i\end{split}
\end{equation*}
This means that we will need to be able to evaluate the gradient of
the basis functions at quadrature points.

\begin{exercise}
Extend \sphinxcode{vandermonde\_matrix()} so that
setting \sphinxcode{grad} to \sphinxcode{True} produces a rank 3 generalised
Vandermonde tensor whose indices represent points, gradient
component and basis function respectively. That is, each entry of
\(V\) is replaced by a vector of the gradient of that polynomial
term. For example, the entry \(x^2y^3\) would be replaced by the
vector \([ 2xy^3, 3x^2y^2 ]\).

The \sphinxcode{test/test\_06\_vandermonde\_matrix\_grad.py} file has tests of this
extension. You should also ensure that you still pass
\sphinxcode{test/test\_03\_vandermonde\_matrix.py}.
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
The \sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.transpose.html\#numpy.ndarray.transpose}{\sphinxcode{transpose()}} method of numpy arrays enables
generalised transposes swapping any dimensions.
\end{sphinxadmonition}

\begin{exercise}
Extend \sphinxcode{tabulate()} to
pass the \sphinxcode{grad} argument through to
\sphinxcode{vandermonde\_matrix()}. Then
generalise the matrix product in
\sphinxcode{tabulate()} so that
the result of this function (when \sphinxcode{grad} is true) is a rank 3
tensor:
\begin{equation*}
\begin{split}\mathrm{T}_{ijk} = \nabla(\phi_j(X_i))\cdot \mathbf{e}_k\end{split}
\end{equation*}
where \(\mathbf{e}_0\ldots\mathbf{e}_{\dim -1}\) is the coordinate
basis on the reference cell.

The \sphinxcode{test/test\_07\_tabulate\_grad.py} script tests this
extension. Once again, make sure you still pass
\sphinxcode{test/test\_05\_tabulate.py}
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
The \sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html\#numpy.einsum}{\sphinxcode{numpy.einsum()}} function implements generalised tensor
contractions using \sphinxhref{http://mathworld.wolfram.com/EinsteinSummation.html}{Einstein summation notation}. For
example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{A} \PYG{o}{=} \PYG{n}{numpy}\PYG{o}{.}\PYG{n}{einsum}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ijk,jl\PYGZhy{}\PYGZgt{}ilk}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{T}\PYG{p}{,} \PYG{n}{C}\PYG{p}{)}
\end{sphinxVerbatim}

is equivalent to \(A_{ilk} = \sum_j T_{ijk} C_{jl}\).
\end{sphinxadmonition}


\section{Interpolating functions to the finite element nodes}
\label{\detokenize{2_finite_elements:interpolating-functions-to-the-finite-element-nodes}}
Recall once again that a function can be represented on a single finite element as:
\begin{equation*}
\begin{split}f = \sum_i f_i\phi_i\end{split}
\end{equation*}
Since \(\{\phi_i\}\) is a nodal basis, it follows immediately that:
\begin{equation*}
\begin{split}f_i = \phi_i^*(f)\end{split}
\end{equation*}
where \(\phi_i^*\) is the node associated with the basis function
\(\phi_i\). Since we are only interested in nodes which are the point
evaluation of their function input, we know that:
\begin{equation*}
\begin{split}f_i = f(X_i)\end{split}
\end{equation*}
where \(X_i\) is the point associated with the \(i\)-th node.

\phantomsection\label{\detokenize{2_finite_elements:ex-interpolate}}
\begin{exercise}
Implement \sphinxcode{interpolate()}.
\end{exercise}
Once you have done this, you can use the script provided to plot
functions of your choice interpolated onto any of the finite
elements you can make:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plot\PYGZus{}interpolate\PYGZus{}lagrange} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sin(2*pi*x[0])}\PYG{l+s+s2}{\PYGZdq{}} \PYG{l+m+mi}{2} \PYG{l+m+mi}{5}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{hint}{Hint:}
You can find help on the arguments to this function with:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plot\PYGZus{}interpolate\PYGZus{}lagrange} \PYG{o}{\PYGZhy{}}\PYG{n}{h}
\end{sphinxVerbatim}
\end{sphinxadmonition}


\chapter{Meshes}
\label{\detokenize{3_meshes::doc}}\label{\detokenize{3_meshes:meshes}}
When employing the finite element method, we represent the domain on
which we wish to solve our PDE as a mesh. In order to work with
meshes, we need to have a somewhat more formal mathematical notion of
a mesh. The mesh concepts we will employ here are loosely based on
those in \phantomsection\label{\detokenize{3_meshes:id1}}{\hyperref[\detokenize{zbibliography:logg2009}]{\sphinxcrossref{{[}Log09{]}}}}, and are typical of mesh representations for the
finite element method.


\section{Mesh entities}
\label{\detokenize{3_meshes:mesh-entities}}
A mesh is composed of \sphinxstyleemphasis{topological entities}, such as vertices, edges,
polygons and polyhedra.

\begin{definition}
The \sphinxstyleemphasis{(topological) dimension} of a mesh is the largest
dimension among all of the topological entities in a mesh.
\end{definition}
In this course we will not consider meshes of manifolds immersed in
higher dimensional spaces (for example the surface of a sphere
immersed in \(\mathbb{R}^3\)) so the topological dimension of the
mesh will always match the geometric dimension of space in which we
are working, so we will simply refer to the \sphinxstyleemphasis{dimension} of the mesh.

\begin{definition}
A topological entity of \sphinxstyleemphasis{codimension} \(n\) is a topological
entity of dimension \(d-n\) where \(d\) is the dimension of the
mesh.
\end{definition}
Armed with these definitions we are able to define names for
topological entities of various dimension and codimension:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
entity name
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
dimension
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
codimension
\unskip}\relax \\
\hline
vertex
&
0
&\\
\hline
edge
&
1
&\\
\hline
face
&
2
&\\
\hline
facet
&&
1
\\
\hline
cell
&&
0
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The cells of a mesh can be polygons or polyhedra of any shape, however
in this course we will restrict ourselves to meshes whose cells are
intervals or triangles. The only other two-dimensional cells
frequently employed are quadrilaterals.

The topological entities of each dimension will be given unique
numbers in order that degrees of freedom can later be associated with
them. We will identify topological entities by an index pair \((d, i)\)
where \(i\) is the index of the entity within the set of \(d\)-dimensional
entities. For example, entity \((0, 10)\) is vertex number 10, and
entity \((1, 10)\) is edge 10. \hyperref[\detokenize{3_meshes:figmesh}]{Fig.\@ \ref{\detokenize{3_meshes:figmesh}}} shows an example
mesh with the topological entities labelled.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{mesh}.pdf}
\caption{A triangular mesh showing labelled topological entities: vertices
(black), edges (red), and cells (blue).}\label{\detokenize{3_meshes:figmesh}}\label{\detokenize{3_meshes:id3}}\end{figure}


\section{Reference cell entities}
\label{\detokenize{3_meshes:reference-cell-entities}}
The reference cells similarly have locally numbered topological
entities, these are shown in \hyperref[\detokenize{3_meshes:figreferenceentities}]{Fig.\@ \ref{\detokenize{3_meshes:figreferenceentities}}}. The
numbering is a matter of convention: that adopted here is that edges
share the number of the opposite vertex. The orientation of the edges
is also shown, this is always from the lower numbered vertex to the
higher numbered one.

The \sphinxcode{ReferenceCell} class stores the
local topology of the reference cell. \sphinxhref{\_modules/fe\_utils/reference\_elements.html}{Read the source} and ensure that you
understand the way in which this information is encoded.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.500\linewidth]{{entities}.pdf}
\caption{Local numbering and orientation of the reference entities.}\label{\detokenize{3_meshes:figreferenceentities}}\label{\detokenize{3_meshes:id4}}\end{figure}


\section{Adjacency}
\label{\detokenize{3_meshes:secadjacency}}\label{\detokenize{3_meshes:adjacency}}
In order to implement the finite element method, we need to integrate
functions over cells, which means knowing which basis functions are
nonzero in a given cell. For the function spaces used in the finite
element method, these basis functions will be the ones whose nodes lie
on the topological entities adjacent to the cell. That is, the
vertices, edges and (in 3D) the faces making up the cell, as well as
the cell itself. One of the roles of the mesh is therefore to provide
a lookup facility for the lower-dimensional mesh entities adjacent to
a given cell.

\begin{definition}
Given a mesh \(M\), then for each \(\dim(M) \geq d_1 > d_2 \geq 0\)
the \sphinxstyleemphasis{adjacency} function \(\operatorname{Adj}_{d_1,d_2}:\,
\mathbb{N}\rightarrow \mathbb{N}^k\) is the function such that:
\begin{equation*}
\begin{split}\operatorname{Adj}_{d_1,d_2}(i) = (i_0, \ldots i_k)\end{split}
\end{equation*}
where \((d_1, i)\) is a topological entity and \((d_2, i_0), \ldots,
(d_2, i_k)\) are the adjacent \(d_2\)-dimensional topological entities
numbered in the corresponding reference cell order. If every cell
in the mesh has the same topology then \(k\) will be fixed for each
\((d_1, d_2)\) pair. The correspondence between the orientation of
the entity \((d_1, i)\) and the reference cell of dimension \(d_1\) is
established by specifying that the vertices are numbered in
ascending order %
\begin{footnote}[1]\sphinxAtStartFootnote
The numbering convention adopted here is very
convenient, but only works for meshes composed
of simplices (vertices, intervals, triangles
and tetrahedra). A more complex convention
would be required to support quadrilateral
meshes.
%
\end{footnote}. That is, for any entity \((d_1, i)\):
\begin{equation*}
\begin{split}(i_0, \ldots i_k) = \operatorname{Adj}_{d_1,0}(i) \quad \Longrightarrow \quad i_0 < \ldots <i_k\end{split}
\end{equation*}
A consequence of this convention is that the global orientation of
all the entities making up a cell also matches their local
orientation.
\end{definition}
\begin{example}
In the mesh shown in \hyperref[\detokenize{3_meshes:figmesh}]{Fig.\@ \ref{\detokenize{3_meshes:figmesh}}} we have:
\begin{equation*}
\begin{split}\operatorname{Adj}_{2,0}(3) = (1,5,8).\end{split}
\end{equation*}
In other words, vertices 1, 5 and 8 are adjacent to cell 3. Similarly:
\begin{equation*}
\begin{split}\operatorname{Adj}_{2,1}(3) = (11,5,9).\end{split}
\end{equation*}
Edges 11, 5, and 9 are local edges 0, 1, and 2 of cell 3.
\end{example}

\section{Mesh geometry}
\label{\detokenize{3_meshes:mesh-geometry}}
The features of meshes we have so far considered are purely
topological: they deal with the adjacency relationships between
topological entities, but do not describe the locations of those
entities in space. Provided we restrict our attention to meshes in
which the element edges are straight (ie not curved), we can represent
the geometry of the mesh by simply recording the coordinates of the
vertices. The positions of the higher dimensional entities then just
interpolate the vertices of which they are composed. We will later
observe that this is equivalent to representing the geometry in a
vector-valued piecewise linear finite element space.


\section{A mesh implementation in Python}
\label{\detokenize{3_meshes:a-mesh-implementation-in-python}}
The \sphinxcode{Mesh} class provides an implementation of
mesh objects in 1 and 2 dimensions. Given the list of vertices making
up each cell, it constructs the rest of the adjacency function. It
also records the coordinates of the vertices.

The \sphinxcode{UnitSquareMesh} class creates a
\sphinxcode{Mesh} object corresponding to a regular
triangular mesh of a unit square. Similarly, the
\sphinxcode{UnitIntervalMesh} class performs the
corresponding (rather trivial) function for a unit one dimensional
mesh.

You can observe the numbering of mesh entities in these meshes using
the \sphinxcode{plot\_mesh} script. Run:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plot\PYGZus{}mesh} \PYG{o}{\PYGZhy{}}\PYG{n}{h}
\end{sphinxVerbatim}

for usage instructions.


\chapter{Function spaces: associating data with meshes}
\label{\detokenize{4_function_spaces::doc}}\label{\detokenize{4_function_spaces:function-spaces-associating-data-with-meshes}}
A finite element space over a mesh is constructed by associating a
finite element with each cell of the mesh. Will refer to the basis
functions of this finite element space as \sphinxstyleemphasis{global} basis functions,
while those of the finite element itself we will refer to as \sphinxstyleemphasis{local}
basis functions. We can establish the relationship between the finite
element and each cell of the mesh by associating the nodes (and
therefore the local basis functions) of the finite element with the
topological entities of the mesh. This is a two stage process. First,
we associate the nodes of the finite element with the local
topological entities of the reference cell. This is often referred to
as \sphinxstyleemphasis{local numbering}. Then we associate the correct number of degrees
of freedom with each global mesh entity. This is the \sphinxstyleemphasis{global
numbering}.


\section{Local numbering and continuity}
\label{\detokenize{4_function_spaces:local-numbering-and-continuity}}
Which nodes should be associated with which topological entities? The
answer to this question depends on the degree of continuity required
between adjacent cells. The nodes associated with topological entites
on the boundaries of cells (the vertices in one dimension, the
vertices and edges in two dimensions, and the vertices, edges and
faces in three dimensions) are shared between cells. The basis
functions associated with nodes on the cell boundary will therefore be
continuous between the cells which share that boundary.

For the Lagrange element family, we require global \(C_0\)
continuity. This implies that the basis functions are continuous
everywhere. This has the following implications for the association of
basis functions with local topological entites:
\begin{description}
\item[{vertices}] \leavevmode
At the function vertices we can achieve continuity by requiring
that there be a node associated with each mesh vertex. The basis
function associated with that node will therefore be continuous. Since
we have a nodal basis, all the other basis functions will vanish at
the vertex so the global space will be continuous at this point.

\item[{edges}] \leavevmode
Where the finite element space has at least 2 dimensions we need to
ensure continuity along edges. The restriction of a degree \(p\)
polynomial over a \(d\)-dimensional cell to an edge of that cell will
be a one dimensional degree \(p\) polynomial. To fully specify this
polynomial along an edge requires \(p+1\) nodes. However there will
already be two nodes associated with the vertices of the edge, so
\(p-1\) additional nodes will be associated with the edge.

\item[{faces}] \leavevmode
For three-dimensional (tetrahedral) elements, the basis
functions must also be continuous across faces. This requires that
sufficient nodes lie on the face to fully specify a two dimensional
degree \(p\) polynomial. However the vertices and edges of the face
already have nodes associated with them, so the number of nodes
required to be associated with the face itself is actually the
number required to represent a degree \(p-2\) polynomial in two
dimensions: \(\begin{pmatrix}p-1\\ 2\end{pmatrix}\).

\end{description}

This pattern holds more generally: for a \(C_0\) function space, the
number of nodes which must be associated with a local topological
entity of degree \(d\) is \(\begin{pmatrix}p-1\\ d\end{pmatrix}\).

\hyperref[\detokenize{4_function_spaces:figlagrange-nodes}]{Fig.\@ \ref{\detokenize{4_function_spaces:figlagrange-nodes}}} illustrates the association of nodes with
reference entities for Lagrange elements on triangles. The numbering
of nodes will depend on how
\sphinxcode{lagrange\_points()} is implemented. The
numbering used here is just one of the obvious choices.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.700\linewidth]{{lagrange_nodes}.pdf}
\caption{Association of nodes with reference entities for the degree 1, 2,
and 3 equispaced Lagrange elements on triangles. Black nodes are
associated with vertices, red nodes with edges and blue nodes with
the cell (face). The numbering of the nodes is arbitrary.}\label{\detokenize{4_function_spaces:figlagrange-nodes}}\label{\detokenize{4_function_spaces:id2}}\end{figure}


\section{Implementing local numbering}
\label{\detokenize{4_function_spaces:implementing-local-numbering}}
Local numbering can be implemented by adding an additional data
structure to the \sphinxcode{FiniteElement}
class. For each local entity this must record the local nodes
associated with that entity. This can be achieved using a dictionary
of dictionaries structure. For example employing the local numbering
of nodes employed in \hyperref[\detokenize{4_function_spaces:figlagrange-nodes}]{Fig.\@ \ref{\detokenize{4_function_spaces:figlagrange-nodes}}}, the \sphinxcode{entity\_node}
dictionary for the degree three equispaced Lagrange element on a triangle is
given by:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{entity\PYGZus{}node} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+m+mi}{0}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+m+mi}{0}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
                   \PYG{l+m+mi}{1}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{,}
                   \PYG{l+m+mi}{2}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{9}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
               \PYG{l+m+mi}{1}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+m+mi}{0}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{8}\PYG{p}{]}\PYG{p}{,}
                   \PYG{l+m+mi}{1}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{7}\PYG{p}{]}\PYG{p}{,}
                   \PYG{l+m+mi}{2}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
               \PYG{l+m+mi}{2}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+m+mi}{0}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{5}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Note that the order of the nodes in each list is important: it must
always consistently reflect the orientation of the relevant entity in
order that all the cells which share that entity consistently
interpret the nodes. In this case this has been achieved by listing
the nodes in order given by the direction of the orientation of each edge.

\begin{exercise}
Extend the \sphinxcode{\_\_init\_\_()} method of
\sphinxcode{LagrangeElement} so that it
passes the correct \sphinxcode{entity\_node} dictionary to the
\sphinxcode{FiniteElement} it creates.

The \sphinxcode{test/test\_08\_entity\_nodes.py} script tests this functionality.
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
You can either work out the right algorithm to generate
\sphinxcode{entity\_nodes} with the right node indices, or you can modify
\sphinxcode{lagrange\_points()} so that it
produces the nodes in entity order, thus making the construction of
\sphinxcode{entity\_nodes} straightforward.

You may find the
\sphinxcode{point\_in\_entity()}
method of the \sphinxcode{ReferenceCell}
class useful.
\end{sphinxadmonition}


\section{Global numbering}
\label{\detokenize{4_function_spaces:global-numbering}}
Given a mesh and a finite element, the global numbering task is to
uniquely associate the appropriate number of global node numbers with
each global entity. One such numbering %
\begin{footnote}[1]\sphinxAtStartFootnote
Many correct global numberings are possible,
that presented here is simple and correct, but not
optimal from the perspective of the memory
layout of the resulting data.
%
\end{footnote} is to
allocate global numbers in ascending entity dimension order, and
within each dimension in order of the index of each global topological
entity. The formula for the first global node associated with entity
\((d, i)\) is then:
\begin{equation*}
\begin{split}G(d, i) = \left(\sum_{\delta < d} N_\delta E_\delta\right) + iN_d\end{split}
\end{equation*}
where \(N_d\) is the number of nodes which this finite element
associates with each entity of dimension \(d\), and \(E_d\) is the number
of dimension \(d\) entities in the mesh. The full list of nodes
associated with entity \((d, i)\) is therefore:

\phantomsection\label{\detokenize{4_function_spaces:equation-4_function_spaces:0}}\begin{equation}\label{equation:4_function_spaces:4_function_spaces:0}
\begin{split}[G(d, i), \ldots, G(d,i) + N_d - 1]\end{split}
\end{equation}

\section{The cell-node map}
\label{\detokenize{4_function_spaces:the-cell-node-map}}\label{\detokenize{4_function_spaces:cell-node}}
The primary use to which we wish to put the finite element spaces we
are constructing is, naturally, the solution of finite element
problems. The principle operation we will therefore need to support is
integration over the mesh of mathematical expressions involving
functions in finite element spaces. This will be accomplished by
integrating over each cell in turn, and then summing over all
cells. This means that a key operation we will need is to find the
nodes associated with a given cell.

It is usual in finite element software to explicitly store the map
from cells to adjacent nodes as a two-dimensional array with one row
corresponding to each cell, and with columns corresponding to the
local node numbers. The entries in this map will have the following values:

\phantomsection\label{\detokenize{4_function_spaces:equation-eqcellnode}}\begin{equation}\label{equation:4_function_spaces:eqcellnode}
\begin{split}M[c, e(\delta, \epsilon)] = [G(\delta, i), \ldots, G(\delta,i) + N_\delta - 1] \qquad\forall 0\leq\delta\leq\dim(c), \forall 0\leq\epsilon < \hat{E}_\delta\end{split}
\end{equation}
where:

\phantomsection\label{\detokenize{4_function_spaces:equation-4_function_spaces:1}}\begin{equation}\label{equation:4_function_spaces:4_function_spaces:1}
\begin{split}i = \operatorname{Adj}_{\dim(c), \delta}[c, \epsilon],\end{split}
\end{equation}
\(e(\delta, \epsilon)\) is the local entity-node list for this finite
element for the \((\delta, \epsilon)\) local entity,
\(\operatorname{Adj}\) has the meaning given under {\hyperref[\detokenize{3_meshes:secadjacency}]{\sphinxcrossref{\DUrole{std,std-ref}{Adjacency}}}},
\(\hat{E}_\delta\) is the number of dimension \(\delta\) entities in each
cell, and \(G\) and \(N\) have the meanings given above. This algorithm
requires a trivial extension to adjacency:

\phantomsection\label{\detokenize{4_function_spaces:equation-4_function_spaces:2}}\begin{equation}\label{equation:4_function_spaces:4_function_spaces:2}
\begin{split}\operatorname{Adj}_{\dim(c),\dim(c)}[c, 0] = c\end{split}
\end{equation}
\begin{sphinxadmonition}{hint}{Hint:}
In {\hyperref[\detokenize{4_function_spaces:equation-eqcellnode}]{\sphinxcrossref{(2)}}}, notice that for each value of \(\delta\) and
\(\epsilon\), \(e(\delta, \epsilon)\) is a vector of indices, so the
equation sets the value of zero, one, or more defined entries in row \(c\)
of \(M\) for each \(\delta\) and \(\epsilon\).
\end{sphinxadmonition}


\section{Implementing function spaces in Python}
\label{\detokenize{4_function_spaces:implementing-function-spaces-in-python}}
As noted above, a finite element space associates a mesh and a finite
element, and contains (in some form) a global numbering of the nodes.

\phantomsection\label{\detokenize{4_function_spaces:ex-function-space}}
\begin{exercise}
Implement the \sphinxcode{\_\_init\_\_()} method of
\sphinxcode{fe\_utils.function\_spaces.FunctionSpace}. The key operation
is to set
\sphinxcode{cell\_nodes} using
{\hyperref[\detokenize{4_function_spaces:equation-eqcellnode}]{\sphinxcrossref{(2)}}}.

You can plot the numbering you have created with the
\sphinxcode{plot\_function\_space\_nodes} script. As usual, run the
script passing the \sphinxcode{-h} option to discover the required
arguments.
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
Many of the terms in {\hyperref[\detokenize{4_function_spaces:equation-eqcellnode}]{\sphinxcrossref{(2)}}} are implemented in the
objects in \sphinxcode{fe\_utils}. For example:
\begin{itemize}
\item {} 
\(\operatorname{Adj}_{\dim(c), \delta}\) is implemented by the
\sphinxcode{adjacency()} method of the
\sphinxcode{Mesh}.

\item {} 
You have \(e(\delta, \epsilon)\) as
\sphinxcode{entity\_nodes}. Note
that in this case you need separate square brackets for each
index:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{element}\PYG{o}{.}\PYG{n}{entity\PYGZus{}nodes}\PYG{p}{[}\PYG{n}{delta}\PYG{p}{]}\PYG{p}{[}\PYG{n}{epsilon}\PYG{p}{]}
\end{sphinxVerbatim}

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{hint}{Hint:}
\sphinxcode{cell\_nodes} needs to
be integer-valued. If you choose to use \sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html\#numpy.zeros}{\sphinxcode{numpy.zeros()}}
to create a matrix which you then populate with values, you
need to explicitly specify that you want a matrix of
integers. This can be achieved by passing the \sphinxcode{dtype} argument
to \sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html\#numpy.zeros}{\sphinxcode{numpy.zeros()}}. For example \sphinxcode{numpy.zeros((nrows, ncols), dtype=int)}.
\end{sphinxadmonition}


\chapter{Functions in finite element spaces}
\label{\detokenize{5_functions::doc}}\label{\detokenize{5_functions:functions-in-finite-element-spaces}}
Recall that the general form of a function in a finite element space is:

\phantomsection\label{\detokenize{5_functions:equation-function}}\begin{equation}\label{equation:5_functions:function}
\begin{split}f(x) = \sum_i f_i \phi_i(x)\end{split}
\end{equation}
Where the \(\phi_i(x)\) are now the global basis functions achieved by
stitching together the local basis functions defined by the
{\hyperref[\detokenize{2_finite_elements:secfinitelement}]{\sphinxcrossref{\DUrole{std,std-ref}{finite element}}}}.


\section{A python implementation of functions in finite element spaces}
\label{\detokenize{5_functions:a-python-implementation-of-functions-in-finite-element-spaces}}
The \sphinxcode{Function} class provides a
simple implementation of function storage. The input is a
\sphinxcode{FunctionSpace} which defines the
mesh and finite element to be employed, to which the
\sphinxcode{Function} adds an array of degree of
freedom values, one for each node in the
\sphinxcode{FunctionSpace}.


\section{Interpolating values into finite element spaces}
\label{\detokenize{5_functions:interpolating-values-into-finite-element-spaces}}
Suppose we have a function \(g(x): \mathbb{R}^n \rightarrow \mathbb{R}\)
which we wish to approximate as a function \(f(x)\) in some finite
element space \(V\). In other words, we want to find the \(f_i\) such that:

\phantomsection\label{\detokenize{5_functions:equation-5_functions:0}}\begin{equation}\label{equation:5_functions:5_functions:0}
\begin{split}\sum_i f_i \phi_i(x) \approx g(x)\end{split}
\end{equation}
The simplest way to do this is to \sphinxstyleemphasis{interpolate} \(g(x)\) onto \(V\). In
other words, we evaluate:

\phantomsection\label{\detokenize{5_functions:equation-5_functions:1}}\begin{equation}\label{equation:5_functions:5_functions:1}
\begin{split}f_i = n_i(g(x))\end{split}
\end{equation}
where \(n_i\) is the node associated with \(\phi_i\). Since we are only
concerned with point evaluation nodes, this is equivalent to:

\phantomsection\label{\detokenize{5_functions:equation-5_functions:2}}\begin{equation}\label{equation:5_functions:5_functions:2}
\begin{split}f_i = g(x_i)\end{split}
\end{equation}
where \(x_i\) is the coordinate vector of the point defining the node
\(n_i\). This looks straightforward, however the \(x_i\) are the \sphinxstyleemphasis{global}
node points, and so far we have only defined the node points in
\sphinxstyleemphasis{local} coordinates on the reference element.


\subsection{Changing coordinates between reference and physical space}
\label{\detokenize{5_functions:coordinates}}\label{\detokenize{5_functions:changing-coordinates-between-reference-and-physical-space}}
We’ll refer to coordinates on the global mesh as being in \sphinxstyleemphasis{physical
space} while those on the reference element are in \sphinxstyleemphasis{local
space}. We’ll use case to distinguish local and global objects, so
local coordinates will be written as \(X\) and global coordinates as
\(x\). The key observation is that within each cell, the global
coordinates are the linear interpolation of the global coordinate
values at the cell vertices. In other words, if \(\{\Psi_j\}\) is the
local basis for the \sphinxstylestrong{linear} lagrange elements on the reference cell and
\(\hat{x}_j\) are the corresponding global vertex locations on a cell \(c\)
then:

\phantomsection\label{\detokenize{5_functions:equation-change}}\begin{equation}\label{equation:5_functions:change}
\begin{split}x = \sum_j \hat{x}_j \Psi_j(X) \quad \forall x \in c.\end{split}
\end{equation}
Remember that we know the location of the nodes in local coordinates,
and we have the
\sphinxcode{tabulate()} method to
evaluate all the basis functions of an element at a known set of
points. So if we write:

\phantomsection\label{\detokenize{5_functions:equation-foo0}}\begin{equation}\label{equation:5_functions:foo0}
\begin{split}A_{i,j} = \Psi_j(X_i)\end{split}
\end{equation}
where \{X\_i\} are the node points of our finite element, then:

\phantomsection\label{\detokenize{5_functions:equation-foo1}}\begin{equation}\label{equation:5_functions:foo1}
\begin{split}x = A\cdot \hat{x}\end{split}
\end{equation}
Where \(\hat{x}\) is the \((\dim+1, \dim)\) array whose rows are the current
element vertex coordinates, and \(x\) is the \((\textrm{nodes}, \dim)\) array whose
rows are the global coordinates of the nodes in the current
element. We can then apply \(g()\) to each row of \(x\) in turn and record
the result as the \sphinxcode{Function} value
for that node.

\begin{sphinxadmonition}{hint}{Hint:}
The observant reader will notice that this algorithm is inefficient
because the function values at nodes on the boundaries of elements
are evaluated more than once. This can be avoided with a little
tedious bookkeeping but we will not concern ourselves with that
here.
\end{sphinxadmonition}


\subsection{Looking up cell coordinates and values}
\label{\detokenize{5_functions:looking-up-cell-coordinates-and-values}}
In the previous section we used the vertex coordinates of a cell to
find the node coordinates, and then we calculated
\sphinxcode{Function} values at those
points. The coordinates are stored in a single long list associated
with the \sphinxcode{Mesh}, and the
\sphinxcode{Function} contains a single long
list of values. We need to use \sphinxstyleemphasis{indirect addressing} to access these
values. This is best illustrated using some Python code.

Suppose \sphinxcode{f} is a \sphinxcode{Function}.
For brevity, we write \sphinxcode{fs = f.function\_space}, the
\sphinxcode{FunctionSpace} associated with
\sphinxcode{f}. Now, we first need a linear element and a corresponding
\sphinxcode{FunctionSpace}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cg1} \PYG{o}{=} \PYG{n}{fe\PYGZus{}utils}\PYG{o}{.}\PYG{n}{LagrangeElement}\PYG{p}{(}\PYG{n}{fs}\PYG{o}{.}\PYG{n}{mesh}\PYG{o}{.}\PYG{n}{cell}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{cg1fs} \PYG{o}{=} \PYG{n}{fe\PYGZus{}utils}\PYG{o}{.}\PYG{n}{FunctionSpace}\PYG{p}{(}\PYG{n}{fs}\PYG{o}{.}\PYG{n}{mesh}\PYG{p}{,} \PYG{n}{cg1}\PYG{p}{)}
\end{sphinxVerbatim}

Then the vertex indices of cell number \sphinxcode{c} in the correct order for the linear Lagrange element are:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{cg1fs}\PYG{o}{.}\PYG{n}{cell\PYGZus{}nodes}\PYG{p}{[}\PYG{n}{c}\PYG{p}{,} \PYG{p}{:}\PYG{p}{]}
\end{sphinxVerbatim}

and therefore the set of coordinate vectors for the vertices of
element \sphinxcode{c} are:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fs}\PYG{o}{.}\PYG{n}{mesh}\PYG{o}{.}\PYG{n}{vertex\PYGZus{}coords}\PYG{p}{[}\PYG{n}{cg1fs}\PYG{o}{.}\PYG{n}{cell\PYGZus{}nodes}\PYG{p}{[}\PYG{n}{c}\PYG{p}{,} \PYG{p}{:}\PYG{p}{]}\PYG{p}{,} \PYG{p}{:}\PYG{p}{]}
\end{sphinxVerbatim}

That is, the \sphinxcode{cg1fs.cell\_nodes} array is used to look up the right
vertex coordinates. By a similar process we can access the values
associated with the nodes of element \sphinxcode{c}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{f}\PYG{o}{.}\PYG{n}{values}\PYG{p}{[}\PYG{n}{fs}\PYG{o}{.}\PYG{n}{cell\PYGZus{}nodes}\PYG{p}{[}\PYG{n}{c}\PYG{p}{,} \PYG{p}{:}\PYG{p}{]}\PYG{p}{]}
\end{sphinxVerbatim}


\subsection{A Python implementation of interpolation}
\label{\detokenize{5_functions:a-python-implementation-of-interpolation}}
Putting together the change of coordinates with the right indirect
addressing, we can provide the
\sphinxcode{Function} class with a
\sphinxcode{interpolate()} method which
interpolates a user-provided function onto the
\sphinxcode{Function}.

\begin{exercise}
Read and understand the
\sphinxcode{interpolate()} method. Use
\sphinxcode{plot\_sin\_function} to investigate interpolating different
functions onto finite element spaces at differering resolutions and
polynomial degrees.
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
There is no implementation work associated with this exercise, but
the programming constructs used in
\sphinxcode{interpolate()} will be
needed when you implement integration.
\end{sphinxadmonition}


\section{Integration}
\label{\detokenize{5_functions:id1}}\label{\detokenize{5_functions:integration}}
We now come to one of the fundamental operations in the finite element
method: integrating a \sphinxcode{Function} over
the domain. The full finite element method actually requires the
integration of expressions of unknown test and trial functions, but we
will start with the more straightforward case of integrating a single,
known, \sphinxcode{Function} over a domain
\(\Omega\):

\phantomsection\label{\detokenize{5_functions:equation-5_functions:3}}\begin{equation}\label{equation:5_functions:5_functions:3}
\begin{split}\int_\Omega f \mathrm{d} x \quad f \in V\end{split}
\end{equation}
where \(\mathrm{d}x\) should be understood as being the volume measure
with the correct dimension for the domain and \(V\) is some finite
element space over \(\Omega\). We can express this integral as a sum of
integrals over individual cells:

\phantomsection\label{\detokenize{5_functions:equation-integral_sum}}\begin{equation}\label{equation:5_functions:integral_sum}
\begin{split}\int_\Omega f \mathrm{d} x = \sum_{c\in\Omega} \int_c f \mathrm{d} x.\end{split}
\end{equation}
So we have in fact reduced the integration problem to the problem of
integrating \(f\) over each cell. In {\hyperref[\detokenize{1_quadrature::doc}]{\sphinxcrossref{\DUrole{doc}{a previous part}}}}
of the module we implemented quadrature rules which enable us to
integrate over specified reference cells. If we can express the
integral over some arbitrary cell \(c\) as an integral over a reference
cell \(c_0\) then we are done. In fact this simply requires us to employ
the change of variables formula for integration:

\phantomsection\label{\detokenize{5_functions:equation-5_functions:4}}\begin{equation}\label{equation:5_functions:5_functions:4}
\begin{split}\int_{c} f(x) \mathrm{d} x = \int_{c_0} f(X) |J|\mathrm{d} X\end{split}
\end{equation}
where \(|J|\) is the absolute value of the determinant of the Jacobian
matrix. \(J\) is given by:

\phantomsection\label{\detokenize{5_functions:equation-jacobian_def}}\begin{equation}\label{equation:5_functions:jacobian_def}
\begin{split}J_{\alpha\beta} = \frac{\partial x_\alpha}{\partial X_\beta}.\end{split}
\end{equation}
\begin{sphinxadmonition}{hint}{Hint:}
We will generally adopt the convention of using Greek letters to
indicate indices in spatial dimensions, while we will use Roman
letters in the sequence \(i,j,\ldots\) for basis function indices. We
will continue to use \(q\) for the index over the quadrature points.
\end{sphinxadmonition}

Evaluating {\hyperref[\detokenize{5_functions:equation-jacobian_def}]{\sphinxcrossref{(11)}}} depends on having an expression for \(x\) in
terms of \(X\). Fortunately, {\hyperref[\detokenize{5_functions:equation-change}]{\sphinxcrossref{(5)}}} is exactly this expression,
and applying the usual rule for differentiating functions in finite
element spaces produces:

\phantomsection\label{\detokenize{5_functions:equation-jacobian}}\begin{equation}\label{equation:5_functions:jacobian}
\begin{split}J_{\alpha\beta} = \sum_j (\tilde{x}_j)_\alpha \nabla_\beta\Psi_j(X)\end{split}
\end{equation}
where \(\{\Psi_j\}\) is once again the degree 1 Lagrange basis and
\(\{\tilde{x}_j\}\) are the coordinates of the corresponding vertices of
cell \(c\). The presence of \(X\) in {\hyperref[\detokenize{5_functions:equation-jacobian}]{\sphinxcrossref{(12)}}} implies that the
Jacobian varies spatially across the reference cell. However since
\(\{\Psi_j\}\) is the degree 1 Lagrange basis, the gradients of the
basis functions are constant over the cell and so it does not matter
at which point in the cell the Jacobian is evaluated. For example we
might choose to evaluate the Jacobian at the cell origin \(X=0\).

\begin{sphinxadmonition}{hint}{Hint:}
When using simplices with curved sides, and on all but the simplest
quadrilateral or hexahedral meshes, the change of coordinates
will not be affine. In that case, to preserve full accuracy it will be
necessary to compute the Jacobian at every quadrature
point. However, non-affine coordinate transforms are beyond the
scope of this course.
\end{sphinxadmonition}


\subsection{Expressing the function in the finite element basis}
\label{\detokenize{5_functions:expressing-the-function-in-the-finite-element-basis}}
Let \(\{\Phi_i(X)\}\) be a \sphinxstylestrong{local} basis for \(V\) on the reference element
\(c_0\). Then our integral becomes:

\phantomsection\label{\detokenize{5_functions:equation-5_functions:5}}\begin{equation}\label{equation:5_functions:5_functions:5}
\begin{split}\int_c f(x)\mathrm{d}x  = \int_{c_0} \sum_i F(M(c,i))\,\Phi_i(X)\, |J|\,\mathrm{d} X\end{split}
\end{equation}
where \(F\) is the vector of global coefficient values of \(f\), and \(M\) is {\hyperref[\detokenize{4_function_spaces:cell-node}]{\sphinxcrossref{\DUrole{std,std-ref}{the cell node map}}}}.


\subsection{Numerical quadrature}
\label{\detokenize{5_functions:numerical-quadrature}}
The actual evaluation of the integral will employ the quadrature rules
we discussed in {\hyperref[\detokenize{1_quadrature::doc}]{\sphinxcrossref{\DUrole{doc}{a previous section}}}}. Let \(\{X_q\},
\{w_q\}\) be a quadrature rule of sufficient degree of precision that
the quadrature is exact. Then:

\phantomsection\label{\detokenize{5_functions:equation-integration}}\begin{equation}\label{equation:5_functions:integration}
\begin{split}\int_c f(x)\mathrm{d}x  = \sum_q \sum_i F(M(c,i))\,\Phi_i(X_q)\, |J|\,w_q\end{split}
\end{equation}

\subsection{Implementing integration}
\label{\detokenize{5_functions:implementing-integration}}
\begin{exercise}
Use {\hyperref[\detokenize{5_functions:equation-jacobian}]{\sphinxcrossref{(12)}}} to implement the
\sphinxcode{jacobian()} method of
\sphinxcode{Mesh}. \sphinxcode{test/test\_09\_jacobian.py} is
available for you to test your results.
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
The \(\nabla_\beta\Psi_j(X)\) factor in {\hyperref[\detokenize{5_functions:equation-jacobian}]{\sphinxcrossref{(12)}}} is the same
for every cell in the mesh. You could make your implementation more
efficient by precalculating this term in the \sphinxcode{\_\_init\_\_()}
method of \sphinxcode{Mesh}.
\end{sphinxadmonition}

\begin{exercise}
Use {\hyperref[\detokenize{5_functions:equation-integral_sum}]{\sphinxcrossref{(9)}}} and {\hyperref[\detokenize{5_functions:equation-integration}]{\sphinxcrossref{(14)}}} to implement
\sphinxcode{integrate()}.
\sphinxcode{test/test\_10\_integrate\_function.py} may be used to test your
implementation.
\end{exercise}
\begin{sphinxadmonition}{hint}{Hint:}
Your method will need to:
\begin{enumerate}
\item {} 
Construct a suitable \sphinxcode{QuadratureRule}.

\item {} 
\sphinxcode{tabulate()} the
basis functions at each quadrature point.

\item {} 
Visit each cell in turn.

\item {} 
Construct the \sphinxcode{jacobian()} for that cell
and take the absolute value of its determinant (\sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.absolute.html\#numpy.absolute}{\sphinxcode{numpy.absolute}}
and \sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.det.html\#numpy.linalg.det}{\sphinxcode{numpy.linalg.det()}} will be useful here).

\item {} 
Sum all of the arrays you have constructed over the correct
indices to a contribution to the integral (\sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html\#numpy.einsum}{\sphinxcode{numpy.einsum()}}
may be useful for this).

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{hint}{Hint:}
You might choose to read ahead before implementing
\sphinxcode{integrate()}, since the
\sphinxcode{errornorm()} function is very similar and may provide a useful
template for your work.
\end{sphinxadmonition}


\chapter{Assembling and solving finite element problems}
\label{\detokenize{6_finite_element_problems::doc}}\label{\detokenize{6_finite_element_problems:assembling-and-solving-finite-element-problems}}
Having constructed functions in finite element spaces and integrated
them over the domain, we now have the tools in place to actually
assemble and solve a simple finite element problem. To avoid having to
explicitly deal with boundary conditions, we choose in the first
instance to solve a Helmholtz problem %
\begin{footnote}[1]\sphinxAtStartFootnote
Strictly speaking this is the positive definite Helmholtz
problem. Changing the sign on \(u\) produces the
indefinite Helmholtz problem, which is significantly
harder to solve.
%
\end{footnote}, find \(u\) in some finite element
space \(V\) such that:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-helmholtz}}\begin{align}\label{equation:6_finite_element_problems:helmholtz}\!\begin{aligned}
- \nabla^2 u + u = f\\
\nabla u \cdot \mathbf{n} = 0 \textrm{ on }\Gamma\\
\end{aligned}\end{align}
where \(\Gamma\) is the domain boundary and \(\mathrm{n}\) is the outward
pointing normal to that boundary. \(f\) is a known function which, for
simplicity, we will assume lies in \(V\). Next, we form the weak form of
this equation by multiplying by a test function in \(V\) and integrating
over the domain. We integrate the Laplacian term by parts. The problem
becomes, find \(u\in V\) such that:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-weak_helmholtz}}\begin{equation}\label{equation:6_finite_element_problems:weak_helmholtz}
\begin{split}\int_\Omega \nabla v \cdot \nabla u + vu\, \mathrm{d} x
- \underbrace{\int_\Gamma v \nabla u \cdot \mathbf{n}\, \mathrm{d} s}_{=0} =
\int_\Omega v f\, \mathrm{d} x \qquad \forall v \in V\end{split}
\end{equation}
If we write \(\{\phi_i\}_{i=0}^{n-1}\) for our basis for \(V\), and recall that
it is sufficient to ensure that {\hyperref[\detokenize{6_finite_element_problems:equation-weak_helmholtz}]{\sphinxcrossref{(2)}}} is satisfied for
each function in the basis then the problem is now, find coefficients \(u_i\) such that:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:0}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:0}
\begin{split}\int_\Omega \sum_{j}\left(\nabla \phi_i \cdot \nabla (u_j\phi_j) + \phi_i u_j\phi_j\right)\, \mathrm{d} x
= \int_\Omega \phi_i\, \sum_k f_k\phi_k\, \mathrm{d} x \qquad \forall\, 0\leq i < n\end{split}
\end{equation}
Since the left hand side is linear in the scalar coefficients \(u_j\), we can move them out of the integral:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:1}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:1}
\begin{split}\sum_{j}\left(\int_\Omega \nabla \phi_i \cdot \nabla \phi_j + \phi_i\phi_j\, \mathrm{d} x\, u_j\right)
= \int_\Omega \phi_i\,\sum_k f_k\phi_k\, \mathrm{d} x \qquad \forall\, 0\leq i < n\end{split}
\end{equation}
We can write this as a matrix equation:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:2}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:2}
\begin{split}\mathrm{A}\mathbf{u} = \mathbf{f}\end{split}
\end{equation}
where:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-eq_lhs}}\begin{equation}\label{equation:6_finite_element_problems:eq_lhs}
\begin{split}\mathrm{A}_{ij} = \int_\Omega \nabla \phi_i \cdot \nabla \phi_j + \phi_i\phi_j\, \mathrm{d} x\end{split}
\end{equation}\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:3}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:3}
\begin{split}\mathbf{u}_j = u_j\end{split}
\end{equation}\phantomsection\label{\detokenize{6_finite_element_problems:equation-eq_rhs}}\begin{equation}\label{equation:6_finite_element_problems:eq_rhs}
\begin{split}\mathbf{f}_i = \int_\Omega \phi_i\,\sum_k f_k\phi_k\, \mathrm{d} x\end{split}
\end{equation}

\section{Assembling the right hand side}
\label{\detokenize{6_finite_element_problems:assembling-the-right-hand-side}}
The assembly of these integrals exploits the same decomposition
property we exploited previously to integrate functions in finite
element spaces. For example, {\hyperref[\detokenize{6_finite_element_problems:equation-eq_rhs}]{\sphinxcrossref{(8)}}} can be rewritten as:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:4}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:4}
\begin{split}\mathbf{f}_i = \sum_c \int_c \phi_i \,\sum_k f_k\phi_k\,  \mathrm{d} x\end{split}
\end{equation}
This has a practical impact once we realise that only a few basis
functions are non-zero in each element. This enables us to write an
efficient algorithm for right hand side assembly. Assume that at the
start of our algorithm:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:5}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:5}
\begin{split}\mathbf{f}_i = 0.\end{split}
\end{equation}
Now for each cell \(c\), we execute:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:6}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:6}
\begin{split}\mathbf{f}_{M(c, \hat{i})} \stackrel{+}{=} \int_c \Phi_{\hat{i}}\, \left(\sum_{\hat{k}}\,f_{M(c,\hat{k})}\,\Phi_{\hat{k}}\right)\,|J|\,\mathrm{d} X \qquad \forall 0 \leq \hat{i} < N\end{split}
\end{equation}
Where \(M\) is the cell-node map for the finite element space \(V\), \(N\)
is the number of nodes per element in \(V\), and
\(\{\Phi_{\hat{i}}\}_{\hat{i}=0}^{N-1}\) are the local basis
functions. In other words, we visit each cell and conduct the integral
for each local basis function, and add that integral to the total for
the corresponding global basis function.

By choosing a suitable quadrature rule, \(\{X_q\}, \{w_q\}\), we can
write this as:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-rhs_index}}\begin{equation}\label{equation:6_finite_element_problems:rhs_index}
\begin{split}\mathbf{f}_{M(c, \hat{i})} \stackrel{+}{=} \left(\sum_q \Phi(X_q)_{\hat{i}}\, \left(\sum_{\hat{k}}\,f_{M(c,\hat{k})}\,\Phi(X_q)_{\hat{k}}\right)\,w_q\,\right) |J| \qquad \forall 0 \leq \hat{i} < N,\, \forall c\end{split}
\end{equation}

\section{Assembling the left hand side matrix}
\label{\detokenize{6_finite_element_problems:assembling-the-left-hand-side-matrix}}
The left hand side matrix follows a similar pattern, however there are
two new complications. First, we have two unbound indices (\(i\) and
\(j\)), and second, the integral involves derivatives. We will address
the question of derivatives first.


\subsection{Pulling gradients back to the reference element}
\label{\detokenize{6_finite_element_problems:pulling-gradients-back-to-the-reference-element}}
On element \(c\), there is a straightforward relationship between the
local and global bases:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-pullback}}\begin{equation}\label{equation:6_finite_element_problems:pullback}
\begin{split}\phi_{M(c,i)}(x) = \Phi_i(X)\end{split}
\end{equation}
We can also, as we showed in {\hyperref[\detokenize{5_functions:coordinates}]{\sphinxcrossref{\DUrole{std,std-ref}{Changing coordinates between reference and physical space}}}}, express the global
coordinate \(x\) in terms of the local coordinate \(X\).

What about \(\nabla\phi\)? We can write the gradient operator in
component form and apply {\hyperref[\detokenize{6_finite_element_problems:equation-pullback}]{\sphinxcrossref{(13)}}}:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:7}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:7}
\begin{split}\frac{\partial\phi_{M(c,i)}(x)}{\partial x_\alpha} =
\frac{\partial\Phi_i(X)}{\partial{x_\alpha}}\quad \forall\, 0\leq \alpha < \dim\end{split}
\end{equation}
However, the expression on the right involves the gradient of a local
basis function with respect to the global coordinate variable \(x\). We
employ the chain rule to express this gradient with respect to the
local coordinates, \(X\):

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:8}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:8}
\begin{split}\frac{\partial\phi_{M(c,i)}(x)}{\partial x_\alpha} =
\sum_{\beta=0}^{\dim-1}\frac{\partial X_\beta}{\partial x_\alpha}\frac{\partial\Phi_i(X)}{\partial{X_\beta}}\quad \forall\, 0\leq \alpha < \dim\end{split}
\end{equation}
Using the {\hyperref[\detokenize{5_functions:integration}]{\sphinxcrossref{\DUrole{std,std-ref}{definition of the Jacobian}}}}, and
using \(\nabla_x\) and \(\nabla_X\) to indicate the global and local
gradient operators respectively, we can equivalently write this
expression as:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:9}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:9}
\begin{split}\nabla_x \phi_{M(c,i)}(x) = J^{-\mathrm{T}}\nabla_X\Phi_i(X)\end{split}
\end{equation}
where \(J^{-\mathrm{T}} = (J^{-1})^\mathrm{T}\) is the transpose of the
inverse of the cell Jacobian matrix.


\subsection{The assembly algorithm}
\label{\detokenize{6_finite_element_problems:the-assembly-algorithm}}
We can start by pulling back {\hyperref[\detokenize{6_finite_element_problems:equation-eq_lhs}]{\sphinxcrossref{(6)}}} to local coordinates:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:10}}\begin{align}\label{equation:6_finite_element_problems:6_finite_element_problems:10}\!\begin{aligned}
\mathrm{A}_{ij} = 0.\\
\mathrm{A}_{M(c, \hat{i}),M(c, \hat{j})} \stackrel{+}{=}
 \int_c\left( \left(J^{-T}\nabla_X \Phi_{\hat{i}}\right)
   \cdot \left(J^{-T}\nabla_X \Phi_{\hat{j}}\right) + \Phi_{\hat{i}}\Phi_{\hat{j}}\right)|J|\, \mathrm{d} X
   \quad\forall 0\leq \hat{i},\hat{j}< N,\, \forall c\\
\end{aligned}\end{align}
We now employ a suitable quadrature rule, \(\{X_q\}, \{w_q\}\), to
calculate the integral:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-lhs_assemble}}\begin{equation}\label{equation:6_finite_element_problems:lhs_assemble}
\begin{split}\mathrm{A}_{M(c, \hat{i}),M(c, \hat{j})} \stackrel{+}{=}
\sum_q \bigg(\left(J^{-T}\nabla_X \Phi_{\hat{i}}(X_q)\right)
\cdot \left(J^{-T}\nabla_X \Phi_{\hat{j}}(X_q)\right) + \Phi_{\hat{i}}(X_q)\Phi_{\hat{j}}(X_q)\bigg)|J|\,w_q
\quad\forall 0\leq \hat{i},\hat{j}< N,\, \forall c\end{split}
\end{equation}
Some readers may find this easier to read using index notation over
the geometric dimensions:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-lhs_index}}\begin{equation}\label{equation:6_finite_element_problems:lhs_index}
\begin{split}\mathrm{A}_{M(c, \hat{i}),M(c, \hat{j})} \stackrel{+}{=}
\sum_q \left(\sum_{\alpha\beta\gamma}J^{-1}_{\beta\alpha}\left(\nabla_X \Phi_{\hat{i}}(X_q)\right)_\beta\,
J^{-1}_{\gamma\alpha}\left(\nabla_X \Phi_{\hat{j}}(X_q)\right)_\gamma + \Phi_{\hat{i}}(X_q)\Phi_{\hat{j}}(X_q)\right)|J|\,w_q
\quad\forall 0\leq \hat{i},\hat{j}< N,\, \forall c\end{split}
\end{equation}

\subsection{A note on matrix insertion}
\label{\detokenize{6_finite_element_problems:a-note-on-matrix-insertion}}
For each cell \(c\), the right hand sides of equations
{\hyperref[\detokenize{6_finite_element_problems:equation-lhs_assemble}]{\sphinxcrossref{(18)}}} and {\hyperref[\detokenize{6_finite_element_problems:equation-lhs_index}]{\sphinxcrossref{(19)}}} have two free indices,
\(\hat{i}\) and \(\hat{j}\). The equation therefore assembles a local
\(N\times N\) matrix corresponding to one integral for each test
function, trial function pair on the current element. This is then
added to the global matrix at the row and column pairs given by the
cell node map \(M(c, \hat{i})\) and \(M(c, \hat{j})\).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.700\linewidth]{{global_assembly}.pdf}
\caption{Computing integrals for each local test and trial function produces
a local dense (in this case, \(3\times 3\)) matrix. The entries in
this matrix are added to the corresponding global row and column
positions in the global matrix.}\label{\detokenize{6_finite_element_problems:figmatrix-insertion}}\label{\detokenize{6_finite_element_problems:id2}}\end{figure}

\begin{sphinxadmonition}{hint}{Hint:}
One might naïvely expect that if \sphinxcode{nodes} is the vector of global
node numbers for the current cell, \sphinxcode{m} is the matrix of local
integral values and \sphinxcode{A} is the global matrix, then the Python
code might look like:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{A}\PYG{p}{[}\PYG{n}{nodes}\PYG{p}{,} \PYG{n}{nodes}\PYG{p}{]} \PYG{o}{+}\PYG{o}{=} \PYG{n}{m} \PYG{c+c1}{\PYGZsh{} DON\PYGZsq{}T DO THIS!}
\end{sphinxVerbatim}

Unfortunately, \sphinxhref{https://docs.scipy.org/doc/numpy/reference/index.html\#module-numpy}{\sphinxcode{numpy}} interprets this as an instruction to
insert a vector into the diagonal of \sphinxcode{A}, and will complain that
the two-dimensional right hand side does not match the
one-dimensional left hand side. Instead, one has to employ the
\sphinxhref{https://docs.scipy.org/doc/numpy/reference/generated/numpy.ix\_.html\#numpy.ix\_}{\sphinxcode{numpy.ix\_()}} function:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{A}\PYG{p}{[}\PYG{n}{np}\PYG{o}{.}\PYG{n}{ix\PYGZus{}}\PYG{p}{(}\PYG{n}{nodes}\PYG{p}{,} \PYG{n}{nodes}\PYG{p}{)}\PYG{p}{]} \PYG{o}{+}\PYG{o}{=} \PYG{n}{m} \PYG{c+c1}{\PYGZsh{} DO THIS!}
\end{sphinxVerbatim}

No such problem exists for adding values into the global right hand
side vector. If \sphinxcode{l} is the global right hand side vector and
\sphinxcode{v} is the vector of local right hand integrals, then the
following will work just fine:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{l}\PYG{p}{[}\PYG{n}{nodes}\PYG{p}{]} \PYG{o}{+}\PYG{o}{=} \PYG{n}{v}
\end{sphinxVerbatim}
\end{sphinxadmonition}


\subsection{Sparse matrices}
\label{\detokenize{6_finite_element_problems:sparse-matrices}}
Each row of the global matrix corresponds to a single global basis
function. The number of non-zeros in this row is equal to the number
of other basis functions which are non-zero in the elements where the
original basis function is non-zero. The maximum number of non-zeros
on a row may vary from a handful for a low degree finite element to a
few hundred for a fairly high degree element. The important point is
that it is essentially independent of the size of the mesh. This means
that as the number of cells in the mesh increases, the proportion of
the matrix entries on each row which have the value zero increases.

For example, a degree 4 Lagrange finite element space defined on
\(64\times 64\) unit square triangular mesh has about 66000 nodes. The
full global matrix therefore has more that 4 billion entries and, at 8
bytes per matrix entry, will consume around 35 gigabytes of memory!
However, there are actually only around 23 nonzeros per row, so more
than 99.9\% of the entries in the matrix are zeroes.

Instead of storing the complete matrix, sparse matrix formats store
only those entries in the matrix which are nonzero. They also have to
store some metadata to describe where in the matrix the non-zero
entries are stored. There are various different sparse matrix formats
available, which make different trade-offs between memory usage,
insertion speed, and the speed of different matrix
operations. However, if we make the (conservative) assumption that a
sparse matrix takes 16 bytes to store each nonzero value, instead of 8
bytes, then we discover that in the example above, we would use less
than 25 megabytes to store the matrix. The time taken to solving the
matrix system will also be vastly reduced since operations on zeros
are avoided.

\begin{sphinxadmonition}{hint}{Hint:}
The \sphinxhref{http://scipy.github.io/devdocs/sparse.html\#module-scipy.sparse}{\sphinxcode{scipy.sparse}} package provides convenient interfaces
which enable Python code to employ a variety of sparse matrix
formats using essentially identical operations to the dense matrix
case. The skeleton code already contains commands to construct
empty sparse matrices and to solve the resulting linear system. You
may, if you wish, experiment with choosing other sparse formats
from \sphinxhref{http://scipy.github.io/devdocs/sparse.html\#module-scipy.sparse}{\sphinxcode{scipy.sparse}}, but it is very strongly suggested that
you do \sphinxstylestrong{not} switch to a dense numpy array; unless, that is, you
particularly enjoy running out of memory on your computer!
\end{sphinxadmonition}


\section{The method of manufactured solutions}
\label{\detokenize{6_finite_element_problems:the-method-of-manufactured-solutions}}
When the finite element method is employed to solve Helmholtz problems
arising in science and engineering, the value forcing function \(f\)
will come from the application data. However for the purpose of
testing numerical methods and software, it is exceptionally useful to
be able to find values of \(f\) such that an analytic solution to the
partial differential equation is known. It turns out that there is a
straightforward algorithm for this process. This algorithm is known as
the \sphinxstyleemphasis{method of manufactured solutions}. It has but two steps:
\begin{enumerate}
\item {} 
Choose a function \(\tilde{u}\) which satisfies the boundary
conditions of the PDE.

\item {} 
Substitute \(\tilde{u}\) into the left hand side of
{\hyperref[\detokenize{6_finite_element_problems:equation-helmholtz}]{\sphinxcrossref{(1)}}}. Set \(f\) equal to the result of this calculation,
and now \(\tilde{u}\) is a solution to {\hyperref[\detokenize{6_finite_element_problems:equation-helmholtz}]{\sphinxcrossref{(1)}}}.

\end{enumerate}

To illustrate this algorithm, suppose we wish to construct \(f\) such that:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:11}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:11}
\begin{split}\tilde{u} = \cos(4\pi x_0) x_1^2(1 - x_1)^2\end{split}
\end{equation}
is a solution to {\hyperref[\detokenize{6_finite_element_problems:equation-helmholtz}]{\sphinxcrossref{(1)}}}. It is simple to verify that
\(\tilde{u}\) satisfies the boundary conditions. We then note that:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:12}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:12}
\begin{split}- \nabla^2 \tilde{u} + \tilde{u} = \left((16 \pi^2 + 1) (x_1 - 1)^2 x_1^2 - 12 x_1^2  +12 x_1  - 2\right) \cos(4 \pi x_0)\end{split}
\end{equation}
If we choose:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-f_def}}\begin{equation}\label{equation:6_finite_element_problems:f_def}
\begin{split}f = \left((16 \pi^2 + 1) (x_1 - 1)^2 x_1^2 - 12 x_1^2  +12 x_1  - 2\right) \cos(4 \pi x_0)\end{split}
\end{equation}
then \(\tilde{u}\) is a solution to {\hyperref[\detokenize{6_finite_element_problems:equation-helmholtz}]{\sphinxcrossref{(1)}}}.


\section{Errors and convergence}
\label{\detokenize{6_finite_element_problems:errors-and-convergence}}

\subsection{The \protect\(L^2\protect\) error}
\label{\detokenize{6_finite_element_problems:the-error}}
When studying finite element methods we are freqently concerned with
convergence in the \(L^2\) norm. That is to say, if \(V\) and \(W\) are
finite element spaces defined over the same mesh, and \(f\in V, g\in W\)
then we need to calculate:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:13}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:13}
\begin{split}\sqrt{\int_\Omega (f-g)^2 \mathrm{d} x} = \sqrt{\sum_c\int_c \left(\left(\sum_i f_{M_V(c,i)}\Phi_i\right) - \left(\sum_j g_{M_W(c,j)}\Psi_j\right)\right)^2|J|\mathrm{d} X}\end{split}
\end{equation}
where \(M_V\) is the cell-node map for the space \(V\) and \(M_W\) is the
cell-node map for the space \(W\). Likewise \(\{\Phi_i\}\) is the local
basis for \(V\) and \(\{\Psi_j\}\) is the local basis for \(W\).

A complete quadrature rule for this integral will, due to the square
in the integrand, require a degree of precision equal to twice the
greater of the polynomial degrees of \(V\) and \(W\).


\subsection{Numerically estimating convergence rates}
\label{\detokenize{6_finite_element_problems:numerically-estimating-convergence-rates}}
Using the approximation results from the theory part of the course, we
know that the error term in the finite element solution of the
Helmholtz equation is expected to have the form \(\mathcal{O}(h^{p+1})\)
where \(h\) is the mesh spacing and \(p\) is the polynomial degree of the
finite element space employed. That is to say if \(\tilde{u}\) is the
exact solution to our PDE and \(u_h\) is the solution to our finite
element problem, then for sufficiently small \(h\):

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:14}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:14}
\begin{split}\|u_h - \tilde{u}\|_{L^2} < c h^{p+1}\end{split}
\end{equation}
for some \(c>0\) not dependent on \(h\). Indeed, for sufficiently small
\(h\), there is a \(c\) such that we can write:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:15}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:15}
\begin{split}\|u_h - \tilde{u}\|_{L^2} \approx c h^{p+1}\end{split}
\end{equation}
Suppose we solve the finite element problem for two different (fine)
mesh spacings, \(h_1\) and \(h_2\). Then we have:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:16}}\begin{align}\label{equation:6_finite_element_problems:6_finite_element_problems:16}\!\begin{aligned}
\|u_{h_1} - \tilde{u}\|_{L^2} \approx c h_1^{p+1}\\
\|u_{h_2} - \tilde{u}\|_{L^2} \approx c h_2^{p+1}\\
\end{aligned}\end{align}
or equivalently:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:17}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:17}
\begin{split}\frac{\|u_{h_1} - \tilde{u}\|_{L^2}}{\|u_{h_2} - \tilde{u}\|_{L^2}}
\approx \left(\frac{h_1}{h_2}\right)^{p+1}\end{split}
\end{equation}
By taking logarithms and rearranging this equation, we can produce a
formula which, given the analytic solution and two numerical
solutions, produces an estimate of the rate of convergence:

\phantomsection\label{\detokenize{6_finite_element_problems:equation-6_finite_element_problems:18}}\begin{equation}\label{equation:6_finite_element_problems:6_finite_element_problems:18}
\begin{split}q = \frac{\ln\left(\displaystyle\frac{\|u_{h_1} - \tilde{u}\|_{L^2}}{\|u_{h_2} - \tilde{u}\|_{L^2}}\right)}
{\ln\left(\displaystyle\frac{h_1}{h_2}\right)}\end{split}
\end{equation}

\section{Implementing finite element problems}
\label{\detokenize{6_finite_element_problems:implementing-finite-element-problems}}
\begin{exercise}
\sphinxcode{fe\_utils/solvers/helmholtz.py} contains a partial implementation of
the finite element method to solve {\hyperref[\detokenize{6_finite_element_problems:equation-weak_helmholtz}]{\sphinxcrossref{(2)}}} with \(f\)
chosen as in {\hyperref[\detokenize{6_finite_element_problems:equation-f_def}]{\sphinxcrossref{(22)}}}. Your task is to implement the
\sphinxcode{assemble()} function using {\hyperref[\detokenize{6_finite_element_problems:equation-rhs_index}]{\sphinxcrossref{(12)}}}, and
{\hyperref[\detokenize{6_finite_element_problems:equation-lhs_assemble}]{\sphinxcrossref{(18)}}} or {\hyperref[\detokenize{6_finite_element_problems:equation-lhs_index}]{\sphinxcrossref{(19)}}}. The comments in the
\sphinxcode{assemble()} function provide some guidance as to the steps
involved. You may also wish to consult the \sphinxcode{errornorm()}
function as a guide to the
structure of the code required.

Run:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{fe\PYGZus{}utils}\PYG{o}{/}\PYG{n}{solvers}\PYG{o}{/}\PYG{n}{helmholtz}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{help}
\end{sphinxVerbatim}

for guidance on using the script to view the solution, the analytic
solution and the error in your solution. In addition,
\sphinxcode{test/test\_12\_helmholtz\_convergence.py} contains tests that the
helmholtz solver converges at the correct rate for degree 1, 2 and
3 polynomials.

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxcode{test/test\_12\_helmholtz\_convergence.py} may take many seconds or
even a couple of minutes to run, as it has to solve on some
rather fine meshes in order to check convergence.
\end{sphinxadmonition}
\end{exercise}

\chapter{Dirichlet boundary conditions}
\label{\detokenize{7_boundary_conditions::doc}}\label{\detokenize{7_boundary_conditions:dirichlet-boundary-conditions}}
The Helmholtz problem we solved in the previous part was chosen to
have homogeneous Neumann or \sphinxstyleemphasis{natural} boundary conditions, which can
be implemented simply by cancelling the zero surface integral. We can
now instead consider the case of Dirichlet, or \sphinxstyleemphasis{essential} boundary
conditions. Instead of the Helmholtz problem we solved before, let us
now specify a Poisson problem with homogeneous Dirichlet conditions, find \(u\) in
some finite element space \(V\) such that:

\phantomsection\label{\detokenize{7_boundary_conditions:equation-poisson}}\begin{align}\label{equation:7_boundary_conditions:poisson}\!\begin{aligned}
-\nabla^2 u = f\\
u = 0  \textrm{ on }\Gamma\\
\end{aligned}\end{align}
In order to implement the Dirichlet conditions, we need to decompose
\(V\) into two parts:

\phantomsection\label{\detokenize{7_boundary_conditions:equation-7_boundary_conditions:0}}\begin{equation}\label{equation:7_boundary_conditions:7_boundary_conditions:0}
\begin{split}V = V_0 \oplus V_\Gamma\end{split}
\end{equation}
where \(V_\Gamma\) is the space spanned by those functions in the basis
of \(V\) which are non-zero on \(\Gamma\), and \(V_0\) is the space spanned
by the remaining basis functions (i.e.  those basis functions which
vanish on \(\Gamma\)). It is a direct consequence of the nodal nature of
the basis that the basis functions for \(V_\Gamma\) are those
corresponding to the nodes on \(\Gamma\) while the basis for \(V_0\) is
composed of all the other functions.

We now write the weak form of {\hyperref[\detokenize{7_boundary_conditions:equation-poisson}]{\sphinxcrossref{(1)}}}, find \(u=u_0 + u_\Gamma\)
with \(u_0 \in V_0\) and \(u_\Gamma \in V_\Gamma\) such that:

\phantomsection\label{\detokenize{7_boundary_conditions:equation-7_boundary_conditions:1}}\begin{align}\label{equation:7_boundary_conditions:7_boundary_conditions:1}\!\begin{aligned}
\int_\Omega \nabla v_0 \cdot \nabla (u_0+u_\Gamma) \, \mathrm{d} x
- \underbrace{\int_\Gamma v_0 \nabla (u_0+u_\Gamma) \cdot
\mathbf{n}\, \mathrm{d} s}_{=0} = \int_\Omega v_0\, f\, \mathrm{d} x
\qquad \forall v_0 \in V_0\\
u_\Gamma = 0 \qquad \textrm{ on } \Gamma\\
\end{aligned}\end{align}
There are a number of features of this equation which require some explanation:
\begin{enumerate}
\item {} 
We only test with functions from \(V_0\). This is because it is only
necessary that the differential equation is satisfied on the interior
of the domain: on the boundary of the domain we need only satisfy the
boundary conditions.

\item {} 
The surface integral now cancels because \(v_0\) is guaranteed to be
zero everywhere on the boundary.

\item {} 
The \(u_\Gamma\) definition actually implies that \(u_\Gamma=0\)
everywhere, since all of the nodes in \(V_\Gamma\) lie on the boundary.

\end{enumerate}

This means that the weak form is actually:

\phantomsection\label{\detokenize{7_boundary_conditions:equation-weakpoisson}}\begin{align}\label{equation:7_boundary_conditions:weakpoisson}\!\begin{aligned}
\int_\Omega \nabla v \cdot \nabla u \, \mathrm{d} x
 = \int_\Omega v_0\, f\, \mathrm{d} x
\qquad \forall v_0 \in V_0\\
u_\Gamma = 0\\
\end{aligned}\end{align}

\section{An algorithm for homogeneous Dirichlet conditions}
\label{\detokenize{7_boundary_conditions:an-algorithm-for-homogeneous-dirichlet-conditions}}
The implementation of homogeneous Dirichlet conditions is actually
rather straightforward.
\begin{enumerate}
\item {} 
The system is assembled completely ignoring the Dirichlet conditions.
This results in a global matrix and vector which are correct on the rows
corresponding to test functions in \(V_0\), but incorrect on the \(V_\Gamma\) rows.

\item {} 
The global vector rows corresponding to boundary nodes are set to 0.

\item {} 
The global matrix rows corresponding to boundary nodes are set to 0.

\item {} 
The diagonal entry on each matrix row corresponding to a boundary node is set to 1.

\end{enumerate}

This has the effect of replacing the incorrect boundary rows of the
system with the equation \(u_i = 0\) for all boundary node numbers \(i\).

\begin{sphinxadmonition}{hint}{Hint:}
This algorithm has the unfortunate side effect of making the global
matrix non-symmetric. If a symmetric matrix is required (for
example in order to use a symmetric solver), then forward
substition can be used to zero the boundary columns in the matrix,
but that is beyond the scope of this module.
\end{sphinxadmonition}


\section{Implementing boundary conditions}
\label{\detokenize{7_boundary_conditions:implementing-boundary-conditions}}
Let:
\begin{equation*}
\begin{split}f = \left(16 \pi^2 (x_1 - 1)^2 x_1^2 - 2 (x_1 - 1)^2 - 8 (x_1 - 1) x_1 - 2 x_1^2\right) \sin(4 \pi x_0)\end{split}
\end{equation*}
With this definition, {\hyperref[\detokenize{7_boundary_conditions:equation-weakpoisson}]{\sphinxcrossref{(4)}}} has solution:
\begin{equation*}
\begin{split}u = \sin(4 \pi x_0) (x_1 - 1)^2 x_1^2\end{split}
\end{equation*}
\begin{exercise}
\sphinxcode{fe\_utils/solvers/poisson.py} contains a partial implementation of
this problem. You need to implement the \sphinxcode{assemble()}
function. You should base your implementation on your
\sphinxcode{fe\_utils/solvers/helmholtz.py} but take into account the difference
in the equation, and the boundary conditions. The
\sphinxcode{fe\_utils.solvers.poisson.boundary\_nodes()} function in \sphinxcode{fe\_utils/solvers/poisson.py} is
likely to be helpful in implementing the boundary conditions. As
before, run:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{fe\PYGZus{}utils}\PYG{o}{/}\PYG{n}{solvers}\PYG{o}{/}\PYG{n}{poisson}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{help}
\end{sphinxVerbatim}

for instructions (they are the same as for
\sphinxcode{fe\_utils/solvers/helmholtz.py}). Similarly,
\sphinxcode{test/test\_13\_poisson\_convergence.py} contains convergence tests
for this problem.
\end{exercise}

\section{Inhomogeneous Dirichlet conditions}
\label{\detokenize{7_boundary_conditions:inhomogeneous-dirichlet-conditions}}
The algorithm described here can be extended to inhomogeneous systems
by setting the entries in the global vector to the value of the
boundary condition at the corresponding boundary node. This additional
step is required for the mastery exercise, but will be explained in
more detail in the next section.


\chapter{Nonlinear problems}
\label{\detokenize{8_nonlinear_problems::doc}}\label{\detokenize{8_nonlinear_problems:nonlinear-problems}}
The finite element method may also be employed to numerically solve
\sphinxstyleemphasis{nonlinear} PDEs. In order to do this, we can employ the classical
technique for solving nonlinear systems: we employ an iterative scheme
such as Newton’s method to create a sequence of linear problems whose
solutions converge to the correct solution to the
nonlinear problem.

\begin{sphinxadmonition}{note}{Note:}
This section is the mastery exercise for this module. This exercise
is explicitly intended to test whether you can bring together what
has been learned in the rest of the module in order to go beyond
what has been covered in lectures and labs.
\end{sphinxadmonition}


\section{A model problem}
\label{\detokenize{8_nonlinear_problems:a-model-problem}}
As a simple case of a non-linear PDE, we can consider a steady
non-linear diffusion equation. This is similar to the Poisson problem,
except that the diffusion rate now depends on the value of the
solution:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-diffusion}}\begin{align}\label{equation:8_nonlinear_problems:diffusion}\!\begin{aligned}
-\nabla\cdot\left((u+1)\nabla u\right) = g\\
u = b \textrm{ on } \Gamma\\
\end{aligned}\end{align}
where \(g\) and \(b\) are given functions defined over \(\Omega\) and
\(\Gamma\) respectively.

We can create the weak form of {\hyperref[\detokenize{8_nonlinear_problems:equation-diffusion}]{\sphinxcrossref{(1)}}} by integrating by parts
and taking the boundary conditions into account. The problem becomes,
find \(u\in V\) such that:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-weakdiffusion}}\begin{align}\label{equation:8_nonlinear_problems:weakdiffusion}\!\begin{aligned}
\int_\Omega \nabla v_0 \cdot (u + 1) \nabla u \, \mathrm{d} x = \int_\Omega vg \, \mathrm{d} x \qquad \forall v_0 \in V_0\\
u_\Gamma = b.\\
\end{aligned}\end{align}
Once more, \(V_0\) is the subspace of \(V\) spanned by basis functions which
vanish on the boundary, \(V = V_0 \oplus V_\Gamma\), and \(u = u_0 +
u_\Gamma\) with \(u_0\in V_0\) and \(u_\Gamma\in V_\Gamma\). This is
corresponds directly with the weak form of the Poisson equation we
already met. However, {\hyperref[\detokenize{8_nonlinear_problems:equation-weakdiffusion}]{\sphinxcrossref{(2)}}} is still nonlinear in \(u\) so
we cannot simply substitute \(u = u_i\phi_i\) in order to obtain a
linear matrix system to solve.


\section{Residual form}
\label{\detokenize{8_nonlinear_problems:residual-form}}
The general weak form of a non-linear problem is, find \(u\in V\) such that:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:0}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:0}
\begin{split}f(u; v) = 0 \qquad \forall v \in V\end{split}
\end{equation}
The use of a semicolon is a common convention to indicate that \(f\) is
assumed to be linear in the arguments after the semicolon, but might
be nonlinear in the arguments before the semicolon. In this case,
we observe that \(f\) may be nonlinear in \(u\) but is (by
construction) linear in \(v\).

The function \(f\) is called the \sphinxstyleemphasis{residual} of the nonlinear system. In
essence, \(f(u; v) = 0 \ \forall v\in V\) if and only if \(u\) is a weak
solution to the PDE. Since the residual is linear in \(v\), it suffices
to define the residual for each \(\phi_i\) in the basis of \(V\). For
\(\phi_i\in V_0\), the residual is just the weak form of the equation,
but what do we do for the boundary? The simple answer is that we need
a linear functional which is zero if the boundary condition is
satisfied at this test function, and nonzero otherwise. The simplest
example of such a functional is:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:1}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:1}
\begin{split}f(u; \phi_i) = n_i(u) - n_i(b)\end{split}
\end{equation}
where \(n_i\) is the node associated with basis function \(\phi_i\). For
point evaluation nodes, \(n_i(u)\) is the value of the proposed solution
at node point \(i\) and \(n_i(b)\) is just the boundary condition
evaluated at that same point.

So for our model problem, we now have a full statement of the residual in terms of a basis function \(\phi_i\):

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-residual}}\begin{equation}\label{equation:8_nonlinear_problems:residual}
\begin{split}f(u; \phi_i) = \begin{cases}
   \displaystyle\int_\Omega \nabla \phi_i \cdot \left((u + 1) \nabla u\right) - \phi_i g \, \mathrm{d} x & \phi_i\in V_0\\
   n_i(u) - n_i(b) & \phi_i\in V_\Gamma
\end{cases}\end{split}
\end{equation}
\begin{sphinxadmonition}{hint}{Hint:}
Evaluating the residual requires that the boundary condition be
evaluated at the boundary nodes. A simple (if slightly inefficient)
way to achieve this is to interpolate the boundary condition onto a
function \(\hat{b}\in V\).
\end{sphinxadmonition}


\section{Linearisation and Gâteaux Derivatives}
\label{\detokenize{8_nonlinear_problems:linearisation-and-gateaux-derivatives}}
Having stated our PDE in residual form, we now need to linearise the
problem and thereby employ a technique such as Newton’s method. In
order to linearise the residual, we need to differentiate it with
respect to \(u\). Since \(u\) is not a scalar real variable, but is
instead a function in \(V\), the appropriate form of differentiation is
the Gâteaux Derivative, given by:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:2}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:2}
\begin{split}J(u; v, \hat{u}) = \lim_{\epsilon\rightarrow 0}\frac{f(u+\epsilon\hat{u}; v)-f(u; v)}{\epsilon}.\end{split}
\end{equation}
Here, the new argument \(\hat{u}\in V\) indicates the “direction” in
which the derivative is to be taken. Let’s work through the Gâteaux
Derivative for the residual of our model problem. Assume first that
\(v\in V_0\). Then:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:3}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:3}
\begin{split}\begin{split}
J(u; v, \hat{u}) &= \lim_{\epsilon\rightarrow 0}\frac{\displaystyle\int_\Omega \nabla v \cdot \left((u +\epsilon\hat{u} + 1) \nabla (u + \epsilon\hat{u})\right) - vg \, \mathrm{d} x - \displaystyle\int_\Omega \nabla v \cdot \left((u + 1) \nabla u\right) - vg \, \mathrm{d} x}{\epsilon}\\
&= \lim_{\epsilon\rightarrow 0}\frac{\displaystyle\int_\Omega \nabla v \cdot \left(\epsilon\hat{u} \nabla u + (u + 1) \nabla (\epsilon\hat{u}) + \epsilon\hat{u} \nabla (\epsilon\hat{u})\right) \, \mathrm{d} x}{\epsilon}\\
&= \int_\Omega \nabla v \cdot \left(\hat{u} \nabla u + (u + 1) \nabla \hat{u} \right) \, \mathrm{d} x.\\
\end{split}\end{split}
\end{equation}
Note that, as expected, \(J\) is linear in \(\hat{u}\).

Next, we can work out the boundary case by assuming \(v=\phi_i\), one of the basis functions of \(V_\Gamma\):

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:4}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:4}
\begin{split}\begin{split}
J(u; \phi_i, \hat{u}) &= \lim_{\epsilon\rightarrow 0}\frac{n_i(u+\epsilon\hat{u}) - n_i(b) - \left(n_i(u) - n_i(b)\right)}{\epsilon}\\
&= n_i(\hat{u}) \qquad \textrm{since } n_i(\cdot) \textrm{ is linear.}
\end{split}\end{split}
\end{equation}
Once again, we can observe that \(J\) is linear in \(\hat{u}\). Indeed, if
we choose \(\hat{u} = \phi_j\) for some \(\phi_j\) in the basis if \(V\)
then the definition of a nodal basis gives us:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:5}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:5}
\begin{split}J(u; \phi_i, \phi_j) = \delta_{ij}\end{split}
\end{equation}

\section{A Taylor expansion and Newton’s method}
\label{\detokenize{8_nonlinear_problems:a-taylor-expansion-and-newton-s-method}}
Since we now have the derivative of the residual with respect to a
perturbation to the prospective solution \(u\), we can write the first
terms of a Taylor series approximation for the value of the residual at a perturbed solution \(u+\hat{u}\):

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:6}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:6}
\begin{split}f(u+\hat{u}; v) = f(u; v) + J(u; v, \hat{u}) +\ldots \qquad \forall v\in V.\end{split}
\end{equation}
Now, just as in the scalar case, Newton’s method consists of
approximating the function (the residual) by the first two terms and
solving for the update that will set these terms to zero. In other
words:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:7}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:7}
\begin{split}u^{n+1} = u^n + \hat{u}\end{split}
\end{equation}
where \(\hat{u} \in V\) is the solution to:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-newton_update}}\begin{equation}\label{equation:8_nonlinear_problems:newton_update}
\begin{split}J(u^n; v, \hat{u}) = - f(u^n; v) \qquad \forall v \in V.\end{split}
\end{equation}
In fact, {\hyperref[\detokenize{8_nonlinear_problems:equation-newton_update}]{\sphinxcrossref{(12)}}} is simply a linear finite element
problem! To make this explicit, we can expand \(v\) and \(\hat{u}\) in
terms of basis functions:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:8}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:8}
\begin{split}J(u^n; \phi_i, \phi_j) \hat{u}_j = - f(u^n; \phi_i).\end{split}
\end{equation}
For our nonlinear diffusion problem, the matrix \(J\) is given by:

\phantomsection\label{\detokenize{8_nonlinear_problems:equation-8_nonlinear_problems:9}}\begin{equation}\label{equation:8_nonlinear_problems:8_nonlinear_problems:9}
\begin{split}J(u^n; \phi_i, \phi_j) =
\begin{cases}
\displaystyle\int_\Omega \nabla \phi_i \cdot \left(\phi_j \nabla u^n + (u^n + 1) \nabla \phi_j \right) \, \mathrm{d} x & \phi_i\in V_0\\
\delta_{ij} & \phi_i \in V_\Gamma,
\end{cases}\end{split}
\end{equation}
and the right hand side vector \(f\) is given by {\hyperref[\detokenize{8_nonlinear_problems:equation-residual}]{\sphinxcrossref{(5)}}}. This
matrix, \(J\), is termed the \sphinxstyleemphasis{Jacobian matrix} of \(f\).


\subsection{Stopping criteria for Newton’s method}
\label{\detokenize{8_nonlinear_problems:stopping-criteria-for-newton-s-method}}
Since Newton’s method is an iterative algorithm, it creates a
(hopefully convergent) sequence of approximations to the correct
solution to the original nonlinear problem. How do we know when to
accept the solution and terminate the algorithm?

The answer is that the update, \(\hat{u}\) which is calculated at each
step of Newton’s method is itself an approximation to the error in the
solution. It is therefore appropriate to stop Newton’s method when
this error estimate becomes sufficiently small in the \(L^2\) norm.

The observant reader will observe that \(\hat{u}\) is in fact
an estimate of the error in the \sphinxstyleemphasis{previous} step. This is indeed true:
the Newton step is both an estimate of the previous error and a
correction to that error. However, having calculated the error
estimate, it is utterly unreasonable to not apply the corresponding
correction.

\begin{sphinxadmonition}{note}{Note:}
Another commonly employed stopping mechanism is to consider the
size of the residual \(f\). However, the residual is not actually a
function in \(V\), but is actually a linear operator in \(V^*\). Common
practice would be to identify \(f\) with a function in \(V\) by simply
taking the function whose coefficients match those of \(f\). The
\(L^2\) or \(l^2\) norm is then taken of this function and this value
is used to determine when convergence has occured.

This approach effectively assumes that the Riesz map on \(V\) is the
trivial operator which identifies the basis function
coefficients. This would be legitimate were the inner product on
\(V\) the \(l^2\) dot product. However, since the inner product on \(V\)
is defined by an integral, the mesh resolution is effectively
encoded into \(f\). This means that this approach produces
convergence rates which depend on the level of mesh refinement.

Avoiding this mesh dependency requires the evaluation of an
operator norm or, equivalently, the solution of a linear system in
order to find the Riesz representer of \(f\) in \(V\). However, since
the error-estimator approach given above is both an actual estimate
of the error in the solution, and requires no additional linear
solves, it should be regarded as a preferable approach. For a full
treatment of Newton methods, see \phantomsection\label{\detokenize{8_nonlinear_problems:id1}}{\hyperref[\detokenize{zbibliography:deuflhard2011}]{\sphinxcrossref{{[}Deu11{]}}}}.
\end{sphinxadmonition}


\subsection{Stopping threshold values}
\label{\detokenize{8_nonlinear_problems:stopping-threshold-values}}
What, then, qualifies as a sufficiently small value of our error
estimate? There are two usual approaches:
\begin{description}
\item[{relative tolerance}] \leavevmode
Convergence is deemed to occur when the estimate
becomes sufficiently small compared with the first error estimate
calculated.  This is generally the more defensible approach since
it takes into account the overall scale of the solution. \(10^{-6}\)
would be a reasonably common relative tolerance.

\item[{absolute tolerance}] \leavevmode
Computers employ finite precision arithmetic, so there is a limit
to the accuracy which can ever be achieved. This is a difficult
value to estimate, since it depends on the number and nature of
operations undertaken in the algorithm. A common approach is to set
this to a very small value (e.g. \(10^{-50}\)) initially, in order to
attempt to ensure that the relative tolerance threshold is
hit. Only if it becomes apparent that the problem being solved is
in a regime for which machine precision is a problem is a higher
absolute tolerance set.

\end{description}

It is important to realise that both of these criteria involve making
essentially arbitrary judgements about the scale of error which is
tolerable. There is also a clear trade-off between the level of error
tolerated and the cost of performing a large number of Newton
steps. For realistic problems, it is therefore frequently expedient
and/or necessary to tune the convergence criteria to the particular
case.

In making these judgements, it is also important to remember that the
error in the Newton solver is just one of the many sources of error in
a calculation. It is pointless to expend computational effort in an
attempt to drive the level of error in this component of the solver to
a level which will be swamped by a larger error occurring somewhere
else in the process.


\subsection{Failure modes}
\label{\detokenize{8_nonlinear_problems:failure-modes}}
Just as with the Newton method for scalar problems, Newton iteration
is not guaranteed to converge for all nonlinear problems or for all
initial guesses. If Newton’s method fails to converge, then the
algorithm presented so far constitutes an infinite loop. It is
therefore necessary to define some circumstances in which the
algorithm should terminate having failed to find a solution. Two such
circumstances are commonly employed:
\begin{description}
\item[{maximum iterations}] \leavevmode
It is a reasonable heuristic that Newton’s method has failed if it
takes a very large number of iterations. What constitutes “too
many” is once again a somewhat arbitrary judgement, although if the
approach takes many tens of iterations this should always be cause
for reconsideration!

\item[{diverged error estimate}] \leavevmode
Newton’s method is not guaranteed to produce a sequence of
iterations which monotonically decrease the error, however if the
error estimate has increased to, say, hundreds or thousands of
times its initial value, this would once again be grounds for the
algorithm to fail.

\end{description}

Note that these failure modes are heuristic: having the algorithm
terminate for these reasons is really an instruction to the user to
think again about the problem, the solver, and the initial guess.


\section{Implementing a nonlinear problem}
\label{\detokenize{8_nonlinear_problems:implementing-a-nonlinear-problem}}
\begin{sphinxadmonition}{note}{Note:}
This problem is intentionally stated in more general terms than the
previous ones. It is your responsibility to decide on a code
structure, to derive a method of manufactured solutions answer, and
to create the convergence tests which demonstrate that your
solution is correct.
\end{sphinxadmonition}

\begin{exercise}
The 2018 mastery exercise will be released by week 5 of the term.
\end{exercise}


\begin{sphinxthebibliography}{Cia02}
\bibitem[Cia02]{\detokenize{Cia02}}{\phantomsection\label{\detokenize{zbibliography:ciarlet2002}} 
Philippe G Ciarlet. \sphinxstyleemphasis{The finite element method for elliptic problems}. Elsevier, 2002. \sphinxhref{https://doi.org/10.1137/1.9780898719208}{doi:10.1137/1.9780898719208}.
}
\bibitem[Deu11]{\detokenize{Deu11}}{\phantomsection\label{\detokenize{zbibliography:deuflhard2011}} 
Peter Deuflhard. \sphinxstyleemphasis{Newton Methods for Nonlinear Problems}. Springer, 2011. \sphinxhref{https://doi.org/10.1007/978-3-642-23899-4}{doi:10.1007/978-3-642-23899-4}.
}
\bibitem[Kir04]{\detokenize{Kir04}}{\phantomsection\label{\detokenize{zbibliography:kirby2004}} 
R.C. Kirby. Algorithm 839: fiat, a new paradigm for computing finite element basis functions. \sphinxstyleemphasis{ACM Transactions on Mathematical Software (TOMS)}, 30(4):502\textendash{}516, 2004. \sphinxhref{https://doi.org/10.1145/1039813.1039820}{doi:10.1145/1039813.1039820}.
}
\bibitem[Log09]{\detokenize{Log09}}{\phantomsection\label{\detokenize{zbibliography:logg2009}} 
A. Logg. Efficient representation of computational meshes. \sphinxstyleemphasis{International Journal of Computational Science and Engineering}, 4(4):283 \textendash{} 295, 2009. \sphinxhref{https://doi.org/10.1504/IJCSE.2009.029164}{doi:10.1504/IJCSE.2009.029164}.
}
\end{sphinxthebibliography}


\end{document}
