
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>8. Nonlinear problems &#8212; Finite element course 2018.0 documentation</title>
    <link rel="stylesheet" href="_static/fenics.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script type="text/javascript" src="_static/proof.js"></script>
    <script async="async" type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="9. References" href="zbibliography.html" />
    <link rel="prev" title="7. Dirichlet boundary conditions" href="7_boundary_conditions.html" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

<link rel="stylesheet" href="_static/featured.css">


<link rel="shortcut icon" href="_static/icon.ico" />


  </head><body>
<div class="wrapper">
  <a href="index.html"><img src="_static/banner.png" width="900px" alt="FInAT Project Banner" /></a>
  <div id="access">
    <div class="menu">
      <ul>
          <li class="page_item"><a href="https://github.com/finite-element/finite-element-course" title="GitHub">GitHub</a></li>
      </ul>
    </div><!-- .menu -->
  </div><!-- #access -->
</div><!-- #wrapper -->


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="nonlinear-problems">
<h1>8. Nonlinear problems<a class="headerlink" href="#nonlinear-problems" title="Permalink to this headline">¶</a></h1>
<p>The finite element method may also be employed to numerically solve
<em>nonlinear</em> PDEs. In order to do this, we can apply the classical
technique for solving nonlinear systems: we employ an iterative scheme
such as Newton’s method to create a sequence of linear problems whose
solutions converge to the correct solution to the
nonlinear problem.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>This section is the mastery exercise for this module. This exercise
is explicitly intended to test whether you can bring together what
has been learned in the rest of the module in order to go beyond
what has been covered in lectures and labs.</p>
<p class="last">This exercise is not a part of the third year version of this module.</p>
</div>
<div class="section" id="a-model-problem">
<h2>8.1. A model problem<a class="headerlink" href="#a-model-problem" title="Permalink to this headline">¶</a></h2>
<p>As a simple case of a non-linear PDE, we can consider a steady
non-linear diffusion equation. This is similar to the Poisson problem,
except that the diffusion rate now depends on the value of the
solution:</p>
<div class="math notranslate nohighlight" id="equation-diffusion">
<span class="eqno">(8.1)<a class="headerlink" href="#equation-diffusion" title="Permalink to this equation">¶</a></span>\[ \begin{align}\begin{aligned}-\nabla\cdot\left((u+1)\nabla u\right) = g\\u = b \textrm{ on } \Gamma\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(g\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are given functions defined over <span class="math notranslate nohighlight">\(\Omega\)</span> and
<span class="math notranslate nohighlight">\(\Gamma\)</span> respectively.</p>
<p>We can create the weak form of <a class="reference internal" href="#equation-diffusion">(8.1)</a> by integrating by parts
and taking the boundary conditions into account. The problem becomes,
find <span class="math notranslate nohighlight">\(u\in V\)</span> such that:</p>
<div class="math notranslate nohighlight" id="equation-weakdiffusion">
<span class="eqno">(8.2)<a class="headerlink" href="#equation-weakdiffusion" title="Permalink to this equation">¶</a></span>\[ \begin{align}\begin{aligned}\int_\Omega \nabla v_0 \cdot (u + 1) \nabla u \, \mathrm{d} x = \int_\Omega v_0g \, \mathrm{d} x \qquad \forall v_0 \in V_0\\u_\Gamma = b.\end{aligned}\end{align} \]</div>
<p>Once more, <span class="math notranslate nohighlight">\(V_0\)</span> is the subspace of <span class="math notranslate nohighlight">\(V\)</span> spanned by basis functions which
vanish on the boundary, <span class="math notranslate nohighlight">\(V = V_0 \oplus V_\Gamma\)</span>, and <span class="math notranslate nohighlight">\(u = u_0 +
u_\Gamma\)</span> with <span class="math notranslate nohighlight">\(u_0\in V_0\)</span> and <span class="math notranslate nohighlight">\(u_\Gamma\in V_\Gamma\)</span>. This is
corresponds directly with the weak form of the Poisson equation we
already met. However, <a class="reference internal" href="#equation-weakdiffusion">(8.2)</a> is still nonlinear in <span class="math notranslate nohighlight">\(u\)</span> so
we cannot simply substitute <span class="math notranslate nohighlight">\(u = u_i\phi_i\)</span> in order to obtain a
linear matrix system to solve.</p>
</div>
<div class="section" id="residual-form">
<h2>8.2. Residual form<a class="headerlink" href="#residual-form" title="Permalink to this headline">¶</a></h2>
<p>The general weak form of a non-linear problem is, find <span class="math notranslate nohighlight">\(u\in V\)</span> such that:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-0">
<span class="eqno">(8.3)<a class="headerlink" href="#equation-8-nonlinear-problems-0" title="Permalink to this equation">¶</a></span>\[f(u; v) = 0 \qquad \forall v \in V\]</div>
<p>The use of a semicolon is a common convention to indicate that <span class="math notranslate nohighlight">\(f\)</span> is
assumed to be linear in the arguments after the semicolon, but might
be nonlinear in the arguments before the semicolon. In this case,
we observe that <span class="math notranslate nohighlight">\(f\)</span> may be nonlinear in <span class="math notranslate nohighlight">\(u\)</span> but is (by
construction) linear in <span class="math notranslate nohighlight">\(v\)</span>.</p>
<p>The function <span class="math notranslate nohighlight">\(f\)</span> is called the <em>residual</em> of the nonlinear system. In
essence, <span class="math notranslate nohighlight">\(f(u; v) = 0 \ \forall v\in V\)</span> if and only if <span class="math notranslate nohighlight">\(u\)</span> is a weak
solution to the PDE. Since the residual is linear in <span class="math notranslate nohighlight">\(v\)</span>, it suffices
to define the residual for each <span class="math notranslate nohighlight">\(\phi_i\)</span> in the basis of <span class="math notranslate nohighlight">\(V\)</span>. For
<span class="math notranslate nohighlight">\(\phi_i\in V_0\)</span>, the residual is just the weak form of the equation,
but what do we do for the boundary? The simple answer is that we need
a linear functional which is zero if the boundary condition is
satisfied at this test function, and nonzero otherwise. The simplest
example of such a functional is:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-1">
<span class="eqno">(8.4)<a class="headerlink" href="#equation-8-nonlinear-problems-1" title="Permalink to this equation">¶</a></span>\[f(u; \phi_i) = n_i(u) - n_i(b)\]</div>
<p>where <span class="math notranslate nohighlight">\(n_i\)</span> is the node associated with basis function <span class="math notranslate nohighlight">\(\phi_i\)</span>. For
point evaluation nodes, <span class="math notranslate nohighlight">\(n_i(u)\)</span> is the value of the proposed solution
at node point <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(n_i(b)\)</span> is just the boundary condition
evaluated at that same point.</p>
<p>So for our model problem, we now have a full statement of the residual in terms of a basis function <span class="math notranslate nohighlight">\(\phi_i\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-residual">
<span class="eqno">(8.5)<a class="headerlink" href="#equation-residual" title="Permalink to this equation">¶</a></span>\[\begin{split}f(u; \phi_i) = \begin{cases}
   \displaystyle\int_\Omega \nabla \phi_i \cdot \left((u + 1) \nabla u\right) - \phi_i g \, \mathrm{d} x &amp; \phi_i\in V_0\\
   n_i(u) - n_i(b) &amp; \phi_i\in V_\Gamma
\end{cases}\end{split}\]</div>
<div class="admonition hint">
<p class="first admonition-title">Hint</p>
<p class="last">Evaluating the residual requires that the boundary condition be
evaluated at the boundary nodes. A simple (if slightly inefficient)
way to achieve this is to interpolate the boundary condition onto a
function <span class="math notranslate nohighlight">\(\hat{b}\in V\)</span>.</p>
</div>
</div>
<div class="section" id="linearisation-and-gateaux-derivatives">
<h2>8.3. Linearisation and Gâteaux Derivatives<a class="headerlink" href="#linearisation-and-gateaux-derivatives" title="Permalink to this headline">¶</a></h2>
<p>Having stated our PDE in residual form, we now need to linearise the
problem and thereby employ a technique such as Newton’s method. In
order to linearise the residual, we need to differentiate it with
respect to <span class="math notranslate nohighlight">\(u\)</span>. Since <span class="math notranslate nohighlight">\(u\)</span> is not a scalar real variable, but is
instead a function in <span class="math notranslate nohighlight">\(V\)</span>, the appropriate form of differentiation is
the Gâteaux Derivative, given by:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-2">
<span class="eqno">(8.6)<a class="headerlink" href="#equation-8-nonlinear-problems-2" title="Permalink to this equation">¶</a></span>\[J(u; v, \hat{u}) = \lim_{\epsilon\rightarrow 0}\frac{f(u+\epsilon\hat{u}; v)-f(u; v)}{\epsilon}.\]</div>
<p>Here, the new argument <span class="math notranslate nohighlight">\(\hat{u}\in V\)</span> indicates the “direction” in
which the derivative is to be taken. Let’s work through the Gâteaux
Derivative for the residual of our model problem. Assume first that
<span class="math notranslate nohighlight">\(v\in V_0\)</span>. Then:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-3">
<span class="eqno">(8.7)<a class="headerlink" href="#equation-8-nonlinear-problems-3" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
J(u; v, \hat{u}) &amp;= \lim_{\epsilon\rightarrow 0}\frac{\displaystyle\int_\Omega \nabla v \cdot \left((u +\epsilon\hat{u} + 1) \nabla (u + \epsilon\hat{u})\right) - vg \, \mathrm{d} x - \displaystyle\int_\Omega \nabla v \cdot \left((u + 1) \nabla u\right) - vg \, \mathrm{d} x}{\epsilon}\\
&amp;= \lim_{\epsilon\rightarrow 0}\frac{\displaystyle\int_\Omega \nabla v \cdot \left(\epsilon\hat{u} \nabla u + (u + 1) \nabla (\epsilon\hat{u}) + \epsilon\hat{u} \nabla (\epsilon\hat{u})\right) \, \mathrm{d} x}{\epsilon}\\
&amp;= \int_\Omega \nabla v \cdot \left(\hat{u} \nabla u + (u + 1) \nabla \hat{u} \right) \, \mathrm{d} x.\\
\end{split}\end{split}\]</div>
<p>Note that, as expected, <span class="math notranslate nohighlight">\(J\)</span> is linear in <span class="math notranslate nohighlight">\(\hat{u}\)</span>.</p>
<p>Next, we can work out the boundary case by assuming <span class="math notranslate nohighlight">\(v=\phi_i\)</span>, one of the basis functions of <span class="math notranslate nohighlight">\(V_\Gamma\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-4">
<span class="eqno">(8.8)<a class="headerlink" href="#equation-8-nonlinear-problems-4" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
J(u; \phi_i, \hat{u}) &amp;= \lim_{\epsilon\rightarrow 0}\frac{n_i(u+\epsilon\hat{u}) - n_i(b) - \left(n_i(u) - n_i(b)\right)}{\epsilon}\\
&amp;= n_i(\hat{u}) \qquad \textrm{since } n_i(\cdot) \textrm{ is linear.}
\end{split}\end{split}\]</div>
<p>Once again, we can observe that <span class="math notranslate nohighlight">\(J\)</span> is linear in <span class="math notranslate nohighlight">\(\hat{u}\)</span>. Indeed, if
we choose <span class="math notranslate nohighlight">\(\hat{u} = \phi_j\)</span> for some <span class="math notranslate nohighlight">\(\phi_j\)</span> in the basis if <span class="math notranslate nohighlight">\(V\)</span>
then the definition of a nodal basis gives us:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-5">
<span class="eqno">(8.9)<a class="headerlink" href="#equation-8-nonlinear-problems-5" title="Permalink to this equation">¶</a></span>\[J(u; \phi_i, \phi_j) = \delta_{ij}\]</div>
</div>
<div class="section" id="a-taylor-expansion-and-newton-s-method">
<h2>8.4. A Taylor expansion and Newton’s method<a class="headerlink" href="#a-taylor-expansion-and-newton-s-method" title="Permalink to this headline">¶</a></h2>
<p>Since we now have the derivative of the residual with respect to a
perturbation to the prospective solution <span class="math notranslate nohighlight">\(u\)</span>, we can write the first
terms of a Taylor series approximation for the value of the residual at a perturbed solution <span class="math notranslate nohighlight">\(u+\hat{u}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-6">
<span class="eqno">(8.10)<a class="headerlink" href="#equation-8-nonlinear-problems-6" title="Permalink to this equation">¶</a></span>\[f(u+\hat{u}; v) = f(u; v) + J(u; v, \hat{u}) +\ldots \qquad \forall v\in V.\]</div>
<p>Now, just as in the scalar case, Newton’s method consists of
approximating the function (the residual) by the first two terms and
solving for the update that will set these terms to zero. In other
words:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-7">
<span class="eqno">(8.11)<a class="headerlink" href="#equation-8-nonlinear-problems-7" title="Permalink to this equation">¶</a></span>\[u^{n+1} = u^n + \hat{u}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{u} \in V\)</span> is the solution to:</p>
<div class="math notranslate nohighlight" id="equation-newton-update">
<span class="eqno">(8.12)<a class="headerlink" href="#equation-newton-update" title="Permalink to this equation">¶</a></span>\[J(u^n; v, \hat{u}) = - f(u^n; v) \qquad \forall v \in V.\]</div>
<p>In fact, <a class="reference internal" href="#equation-newton-update">(8.12)</a> is simply a linear finite element
problem! To make this explicit, we can expand <span class="math notranslate nohighlight">\(v\)</span> and <span class="math notranslate nohighlight">\(\hat{u}\)</span> in
terms of basis functions:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-8">
<span class="eqno">(8.13)<a class="headerlink" href="#equation-8-nonlinear-problems-8" title="Permalink to this equation">¶</a></span>\[J(u^n; \phi_i, \phi_j) \hat{u}_j = - f(u^n; \phi_i).\]</div>
<p>For our nonlinear diffusion problem, the matrix <span class="math notranslate nohighlight">\(J\)</span> is given by:</p>
<div class="math notranslate nohighlight" id="equation-8-nonlinear-problems-9">
<span class="eqno">(8.14)<a class="headerlink" href="#equation-8-nonlinear-problems-9" title="Permalink to this equation">¶</a></span>\[\begin{split}J(u^n; \phi_i, \phi_j) =
\begin{cases}
\displaystyle\int_\Omega \nabla \phi_i \cdot \left(\phi_j \nabla u^n + (u^n + 1) \nabla \phi_j \right) \, \mathrm{d} x &amp; \phi_i\in V_0\\
\delta_{ij} &amp; \phi_i \in V_\Gamma,
\end{cases}\end{split}\]</div>
<p>and the right hand side vector <span class="math notranslate nohighlight">\(f\)</span> is given by <a class="reference internal" href="#equation-residual">(8.5)</a>. This
matrix, <span class="math notranslate nohighlight">\(J\)</span>, is termed the <em>Jacobian matrix</em> of <span class="math notranslate nohighlight">\(f\)</span>.</p>
<div class="section" id="stopping-criteria-for-newton-s-method">
<h3>8.4.1. Stopping criteria for Newton’s method<a class="headerlink" href="#stopping-criteria-for-newton-s-method" title="Permalink to this headline">¶</a></h3>
<p>Since Newton’s method is an iterative algorithm, it creates a
(hopefully convergent) sequence of approximations to the correct
solution to the original nonlinear problem. How do we know when to
accept the solution and terminate the algorithm?</p>
<p>The answer is that the update, <span class="math notranslate nohighlight">\(\hat{u}\)</span> which is calculated at each
step of Newton’s method is itself an approximation to the error in the
solution. It is therefore appropriate to stop Newton’s method when
this error estimate becomes sufficiently small in the <span class="math notranslate nohighlight">\(L^2\)</span> norm.</p>
<p>The observant reader will observe that <span class="math notranslate nohighlight">\(\hat{u}\)</span> is in fact
an estimate of the error in the <em>previous</em> step. This is indeed true:
the Newton step is both an estimate of the previous error and a
correction to that error. However, having calculated the error
estimate, it is utterly unreasonable to not apply the corresponding
correction.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Another commonly employed stopping mechanism is to consider the
size of the residual <span class="math notranslate nohighlight">\(f\)</span>. However, the residual is not actually a
function in <span class="math notranslate nohighlight">\(V\)</span>, but is actually a linear operator in <span class="math notranslate nohighlight">\(V^*\)</span>. Common
practice would be to identify <span class="math notranslate nohighlight">\(f\)</span> with a function in <span class="math notranslate nohighlight">\(V\)</span> by simply
taking the function whose coefficients match those of <span class="math notranslate nohighlight">\(f\)</span>. The
<span class="math notranslate nohighlight">\(L^2\)</span> or <span class="math notranslate nohighlight">\(l^2\)</span> norm is then taken of this function and this value
is used to determine when convergence has occured.</p>
<p>This approach effectively assumes that the Riesz map on <span class="math notranslate nohighlight">\(V\)</span> is the
trivial operator which identifies the basis function
coefficients. This would be legitimate were the inner product on
<span class="math notranslate nohighlight">\(V\)</span> the <span class="math notranslate nohighlight">\(l^2\)</span> dot product. However, since the inner product on <span class="math notranslate nohighlight">\(V\)</span>
is defined by an integral, the mesh resolution is effectively
encoded into <span class="math notranslate nohighlight">\(f\)</span>. This means that this approach produces
convergence rates which depend on the level of mesh refinement.</p>
<p class="last">Avoiding this mesh dependency requires the evaluation of an
operator norm or, equivalently, the solution of a linear system in
order to find the Riesz representer of <span class="math notranslate nohighlight">\(f\)</span> in <span class="math notranslate nohighlight">\(V\)</span>. However, since
the error-estimator approach given above is both an actual estimate
of the error in the solution, and requires no additional linear
solves, it should be regarded as a preferable approach. For a full
treatment of Newton methods, see <a class="reference internal" href="zbibliography.html#deuflhard2011" id="id1">[Deu11]</a>.</p>
</div>
</div>
<div class="section" id="stopping-threshold-values">
<h3>8.4.2. Stopping threshold values<a class="headerlink" href="#stopping-threshold-values" title="Permalink to this headline">¶</a></h3>
<p>What, then, qualifies as a sufficiently small value of our error
estimate? There are two usual approaches:</p>
<dl class="docutils">
<dt>relative tolerance</dt>
<dd>Convergence is deemed to occur when the estimate
becomes sufficiently small compared with the first error estimate
calculated.  This is generally the more defensible approach since
it takes into account the overall scale of the solution. <span class="math notranslate nohighlight">\(10^{-6}\)</span>
would be a reasonably common relative tolerance.</dd>
<dt>absolute tolerance</dt>
<dd>Computers employ finite precision arithmetic, so there is a limit
to the accuracy which can ever be achieved. This is a difficult
value to estimate, since it depends on the number and nature of
operations undertaken in the algorithm. A common approach is to set
this to a very small value (e.g. <span class="math notranslate nohighlight">\(10^{-50}\)</span>) initially, in order to
attempt to ensure that the relative tolerance threshold is
hit. Only if it becomes apparent that the problem being solved is
in a regime for which machine precision is a problem is a higher
absolute tolerance set.</dd>
</dl>
<p>It is important to realise that both of these criteria involve making
essentially arbitrary judgements about the scale of error which is
tolerable. There is also a clear trade-off between the level of error
tolerated and the cost of performing a large number of Newton
steps. For realistic problems, it is therefore frequently expedient
and/or necessary to tune the convergence criteria to the particular
case.</p>
<p>In making these judgements, it is also important to remember that the
error in the Newton solver is just one of the many sources of error in
a calculation. It is pointless to expend computational effort in an
attempt to drive the level of error in this component of the solver to
a level which will be swamped by a larger error occurring somewhere
else in the process.</p>
</div>
<div class="section" id="failure-modes">
<h3>8.4.3. Failure modes<a class="headerlink" href="#failure-modes" title="Permalink to this headline">¶</a></h3>
<p>Just as with the Newton method for scalar problems, Newton iteration
is not guaranteed to converge for all nonlinear problems or for all
initial guesses. If Newton’s method fails to converge, then the
algorithm presented so far constitutes an infinite loop. It is
therefore necessary to define some circumstances in which the
algorithm should terminate having failed to find a solution. Two such
circumstances are commonly employed:</p>
<dl class="docutils">
<dt>maximum iterations</dt>
<dd>It is a reasonable heuristic that Newton’s method has failed if it
takes a very large number of iterations. What constitutes “too
many” is once again a somewhat arbitrary judgement, although if the
approach takes many tens of iterations this should always be cause
for reconsideration!</dd>
<dt>diverged error estimate</dt>
<dd>Newton’s method is not guaranteed to produce a sequence of
iterations which monotonically decrease the error, however if the
error estimate has increased to, say, hundreds or thousands of
times its initial value, this would once again be grounds for the
algorithm to fail.</dd>
</dl>
<p>Note that these failure modes are heuristic: having the algorithm
terminate for these reasons is really an instruction to the user to
think again about the problem, the solver, and the initial guess.</p>
</div>
</div>
<div class="section" id="implementing-a-nonlinear-problem">
<h2>8.5. Implementing a nonlinear problem<a class="headerlink" href="#implementing-a-nonlinear-problem" title="Permalink to this headline">¶</a></h2>
<p>This problem will be released in the middle of the term.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2014-2018, David A. Ham and Colin J. Cotter.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.3.
    </div>
  </body>
</html>